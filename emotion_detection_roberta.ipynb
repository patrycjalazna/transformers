{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patrycjalazna/transformers/blob/main/emotion_detection_roberta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsVorHKjEAuS"
      },
      "source": [
        "## ImportyðŸ’…ðŸ»ðŸ’…ðŸ»ðŸ’…ðŸ»"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4mxNeEwETVC",
        "outputId": "caef5a3f-db85-4792-bd61-d9013a0adeb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.12.5\n",
            "  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.1 MB 4.2 MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.10.3\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.3 MB 36.3 MB/s \n",
            "\u001b[?25hCollecting sentencepiece==0.1.96\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.2 MB 15.3 MB/s \n",
            "\u001b[?25hCollecting datasets==1.16.1\n",
            "  Downloading datasets-1.16.1-py3-none-any.whl (298 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298 kB 39.7 MB/s \n",
            "\u001b[?25hCollecting accelerate==0.5.1\n",
            "  Downloading accelerate-0.5.1-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58 kB 6.1 MB/s \n",
            "\u001b[?25hCollecting sacremoses==0.0.46\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895 kB 49.7 MB/s \n",
            "\u001b[?25hCollecting sacrebleu==2.0.0\n",
            "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90 kB 10.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.5) (3.4.2)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 596 kB 37.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.5) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.5) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.5) (1.21.5)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67 kB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.5) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.5) (4.62.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.5) (4.11.0)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.16.1) (6.0.1)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243 kB 48.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets==1.16.1) (0.70.12.2)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1 MB 44.7 MB/s \n",
            "\u001b[?25hCollecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.1.0-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 133 kB 52.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets==1.16.1) (1.3.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets==1.16.1) (0.3.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.46) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.46) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.46) (1.15.0)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu==2.0.0) (0.8.9)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.12.5) (3.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.12.5) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.12.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.12.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.12.5) (3.0.4)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 271 kB 53.2 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 144 kB 51.3 MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94 kB 3.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==1.16.1) (2.0.11)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==1.16.1) (21.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.12.5) (3.7.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.16.1) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.16.1) (2.8.2)\n",
            "Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, pyyaml, fsspec, aiohttp, xxhash, tokenizers, sacremoses, portalocker, huggingface-hub, colorama, transformers, sentencepiece, sacrebleu, datasets, accelerate\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed accelerate-0.5.1 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 colorama-0.4.4 datasets-1.16.1 frozenlist-1.3.0 fsspec-2022.1.0 huggingface-hub-0.4.0 multidict-6.0.2 portalocker-2.4.0 pyyaml-6.0 sacrebleu-2.0.0 sacremoses-0.0.46 sentencepiece-0.1.96 tokenizers-0.10.3 transformers-4.12.5 xxhash-2.0.2 yarl-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install 'transformers==4.12.5' 'tokenizers==0.10.3' 'sentencepiece==0.1.96' 'datasets==1.16.1' 'accelerate==0.5.1' 'sacremoses==0.0.46' 'sacrebleu==2.0.0' 'torch';"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttq7YMKmCGsd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import MSELoss, CrossEntropyLoss, BCEWithLogitsLoss\n",
        "from transformers import RobertaForSequenceClassification, RobertaModel\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "import json\n",
        "from pathlib import Path\n",
        "from typing import Dict, List\n",
        "from datasets import load_dataset\n",
        "import os\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGC7tQxkD_65"
      },
      "source": [
        "## ðŸ¤— Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6i8tCAdDE_X6"
      },
      "source": [
        "Dataset *emotion* jest zbiorem danych angielskich wiadomoÅ›ci na Twitterze zawierajÄ…cych szeÅ›Ä‡ podstawowych emocji: gniew, strach, radoÅ›Ä‡, miÅ‚oÅ›Ä‡, smutek i zaskoczenie."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQhq_Z1oF0cE"
      },
      "source": [
        "Link do datasetu: [hugginface](https://huggingface.co/datasets/emotion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YpVh9EvFkeM"
      },
      "source": [
        "PrzykÅ‚ad:\n",
        "\n",
        "```\n",
        "{\n",
        "    \"label\": 0,\n",
        "    \"text\": \"im feeling quite sad and sorry for myself but ill snap out of it soon\"\n",
        "}\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281,
          "referenced_widgets": [
            "dae071c03da549cdad7eb0b59d85d87a",
            "51724145c0df4dcb88b36d597982705a",
            "3047d03eef75427bbaafd1d7b2a6f8a5",
            "5f89aaa1c32148539cd148a91b52a8d5",
            "2e394268cdc74f75aee9f572106e2a6e",
            "e7a3526ae0c047b296591c2cd4c9139e",
            "7327fcb2e766421a837515e61a06880d",
            "42f489c532b04b53b09bfdaf40bbf35a",
            "4751a4c2a47c4b7794f5700f8e5fbfa3",
            "e21b950052064bad8eda00c73e0d9ea6",
            "992804019c024d0f9cbf9aa64b25a235",
            "1f348c3b23994ec181d45de43dd1ef5f",
            "032ed4e2d9fe4510b5a6a02c569e934d",
            "388603f7569e4be6966b73e8fa45d6cb",
            "fcd5ae574a7b4801b4050d73ae519488",
            "48bb0ef27dc9410cb8265cfba6464f38",
            "fd399a6c439f4f9d8eb26000ca9e1e1d",
            "f0db8e5f4852445d94251854018937df",
            "85d7a510ee2046f2bdff9d49d850df64",
            "bb9632d2d59a401fa7fcc2887da1914a",
            "f5762e87b3c941feb913ccc1d421d8c2",
            "4e10b8a643214c0dabe346269bc40efe",
            "d73c7b25315045f6835bdd06c4b8a3ae",
            "cba05fb4da6340b485d772a03bf81a43",
            "e19affe8ca5045df8cdeee8de2844494",
            "60af17e9f117434fb1d5573e09ae40d3",
            "d06ec525ea3249c1b59f73cbc40dbe24",
            "e16bae913b384ebaac18366a74906a71",
            "710a31601ca543bea660c245757954f4",
            "e8fca2fc409d4b6bb814db712c4fbc0a",
            "3ddced4524cb4ea4a9553f1feb11564e",
            "9a756c46d63149cba8eadf4aec23eb0d",
            "1d61d3ebd3be431b9faec1dc56d2c0a4",
            "945ec2317df14cd0a54c14ca03e59313",
            "647be445b75b437597bcf0eb280685cd",
            "2d0b3e7a7ca7436cb6d826aaffd01bf0",
            "221fe854e4684588a2e86eff6a4593fd",
            "4fd9e34b65944ef9b9ba1cc12e2ce010",
            "e809d345a5064f0c9c83c18caa3b825b",
            "ef80d22b78a649e8bfddfe4feb9f7ad1",
            "d95add2193a24c92b376f203fb380815",
            "6ba72b3a60ac40dba071a1638a468f48",
            "c30221309ca341d1a2fe10063aa75af8",
            "f26e26c72bc74b5689160d7ef477beac",
            "0b9467ed14394c908ff311dff73ba85d",
            "c7a0ee7eac074ee3a2c0db67d04ee0a0",
            "43663f128ea34aaab9fac9d78b76a28d",
            "446af72edb2847d89645b505f062b470",
            "a27d29f0a19b484ba0f6f495992dcefa",
            "aaa0b25715664424868ec42a64d70781",
            "9bc6adc93c144357898953a96850e892",
            "78a19f22fcb5481699169dbebb78a115",
            "4db1b4ffd45246a0ad678138d633df88",
            "1f6c52631a884e1db366eb80c5c30026",
            "491e0a5f5a6f4863a24f099f59ec3517",
            "329f8f633de14ee0b69ed3544b564bcb",
            "30d0fdb50e69427894c52fed2a5aba4e",
            "62d78a6cfe0849388520ac5fb321ba93",
            "438b3bb62894430498e3b58dafafb529",
            "f58d484e22a64b96a5ff8b3ab5034f04",
            "7d708faa40bc4cae973bf270f5c37e34",
            "70b50517a3ef42d9994225677af94d98",
            "09ea1765b2854d9db3d5c5b3c4c8c6f6",
            "97f2b85bec724ac684f49a57eeedb28c",
            "18c5d197ab66492e80adf1fd15b2b673",
            "241318756a36480599b5377da9f2c616",
            "7c158a3c90b748ca88524739c10d8bfd",
            "7018405d174946bf88d2532b9ddb5c0a",
            "990109445da3436190ffdf8c9b1fc2ad",
            "a72c8ec240ec4060bd936a29087d4139",
            "6129960f89fe4d459322962e8a8de9b2",
            "b652b7ecab9b463e95946bfcbe2455b6",
            "b6b9b3cec0c14eaa8a8f3b89c8f192a7",
            "db0342821771491cb0a9aa26b5b611f7",
            "ee0dcd693d484b1bb47ffbfe439dcc7c",
            "8aaa111f35fd46b6afb80d8f16260f63",
            "271546f7444c4773a80f5bced38021a1",
            "d1d7b1a8cc4b439e92c8d35a980678c0",
            "f2e5781231844ccbb0d877477dc9cf1f",
            "923709de50004cdd8a1d8256693e9657",
            "ae5693927605454fa0200eb08ea66ea9",
            "75e4c0dc5c8d45ffb812631582b08e42",
            "27f554d2f9e14968b780b3568297b92d",
            "2e26c94b0d144e9ebf33839338662220",
            "aea48b6a91e64c58911d3fbdf3d6b7e0",
            "e2e4419b43834935a006a62cc0755f91",
            "53aac80dcb1e4c3fa55563cf142e5fe2",
            "9d777c3e664f48a2b208904234dc28d3",
            "2e7541a424ae4258b878d78a83c09295",
            "f3e2bb3ffbde464b94435a6e88b3cfc4",
            "4202443ccecb4e4fa03c7c65018c4740",
            "c54504273ca143e8befb24610ea07cbe",
            "6ba2a510785f4dccac5a4f912cfb891d",
            "5e14afbe9b0f46b3a27cfe2e0ffdd903",
            "8f04498b32944740bd192f1be5154ba8",
            "c3711f7bbaea49db8afd5a0530ac55bf",
            "e447482e8b8f4ec2862fd51005343a37",
            "e923351e7da742b993a35b3af7990f30",
            "e6ca70ed9994422eaa6ac936cc8cd4b0"
          ]
        },
        "id": "du4Zt20cEwKq",
        "outputId": "f907701f-cb93-49de-c494-ad55e43090c2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dae071c03da549cdad7eb0b59d85d87a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.66k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f348c3b23994ec181d45de43dd1ef5f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.61k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration default\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset emotion/default (download: 1.97 MiB, generated: 2.07 MiB, post-processed: Unknown size, total: 4.05 MiB) to /root/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d73c7b25315045f6835bdd06c4b8a3ae",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "945ec2317df14cd0a54c14ca03e59313",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b9467ed14394c908ff311dff73ba85d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "329f8f633de14ee0b69ed3544b564bcb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7c158a3c90b748ca88524739c10d8bfd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1d7b1a8cc4b439e92c8d35a980678c0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset emotion downloaded and prepared to /root/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e7541a424ae4258b878d78a83c09295",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "dataset = load_dataset('emotion')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAlgEwdWGINg"
      },
      "source": [
        "Dane mamy automatycznie podzielone train set, validation set i test set w stosunku 8:1:1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1uh1PJPE-d5",
        "outputId": "f4a41968-91f5-4cbe-b90c-1162b8927e53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 16000\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 2000\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 2000\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "print(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dEWfFojGYu2"
      },
      "source": [
        "NastÄ™pnie tworzymy folder, w ktÃ³rym zapiszemy dane."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hi6YO6kPGU5C"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(\"./data\"):\n",
        "    os.makedirs(\"./data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAaGp1LuGhK0"
      },
      "outputs": [],
      "source": [
        "train_path = Path('data/train.json')\n",
        "valid_path = Path('data/valid.json')\n",
        "test_path = Path('data/test.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBgXI88RGmp-",
        "outputId": "f5348ff5-6005-4ff5-f450-1f017184d462"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 16000\n",
            "Test: 2000\n",
            "Validation: 2000\n"
          ]
        }
      ],
      "source": [
        "data_train_list, data_valid_list, data_test_list = [], [], []\n",
        "\n",
        "for data_line, data_list in [\n",
        "  (dataset['train'], data_train_list),\n",
        "  (dataset['test'], data_test_list),\n",
        "  (dataset['validation'], data_valid_list)\n",
        "]:\n",
        "  for i, data in enumerate(data_line):\n",
        "    line = {\n",
        "      'label': int(data['label']),\n",
        "      'text': data['text'],\n",
        "    }\n",
        "    data_list.append(line)\n",
        "\n",
        "print(f'Train: {len(data_train_list)}')\n",
        "print(f'Test: {len(data_valid_list)}')\n",
        "print(f'Validation: {len(data_test_list)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EA_tgKcTO9lZ"
      },
      "outputs": [],
      "source": [
        "# ZaleÅ¼y czy mapujemy tylko na pozytywne i negatywne czy na 6 co sÄ… w datasecie\n",
        "def get_map_label_translation(num_classes = 6):\n",
        "    '''\n",
        "    Possible numbers [2, 6]\n",
        "    '''\n",
        "    if(num_classes == 2):\n",
        "        return {\n",
        "            0: 'negative',\n",
        "            1: 'positive',\n",
        "            2: 'positive',\n",
        "            3: 'negative',\n",
        "            4: 'negative',\n",
        "            5: 'positive',\n",
        "        }\n",
        "    elif(num_classes == 6):\n",
        "        return {\n",
        "            0: 'sadness',\n",
        "            1: 'joy',\n",
        "            2: 'love',\n",
        "            3: 'anger',\n",
        "            4: 'fear',\n",
        "            5: 'suprise',\n",
        "        }\n",
        "\n",
        "MAP_LABEL_TRANSLATION = get_map_label_translation(6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feE1t9t4G0pn",
        "outputId": "ecf43533-8054-46ab-f6d3-13c0f99a12d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Stats for train set --\n",
            "Label sadness:   4666\n",
            "Label joy:   5362\n",
            "Label love:   1304\n",
            "Label anger:   2159\n",
            "Label fear:   1937\n",
            "Label suprise:    572\n",
            "-- Stats for test set --\n",
            "Label sadness:    581\n",
            "Label joy:    695\n",
            "Label love:    159\n",
            "Label anger:    275\n",
            "Label fear:    224\n",
            "Label suprise:     66\n",
            "-- Stats for validation set --\n",
            "Label sadness:    550\n",
            "Label joy:    704\n",
            "Label love:    178\n",
            "Label anger:    275\n",
            "Label fear:    212\n",
            "Label suprise:     81\n"
          ]
        }
      ],
      "source": [
        "data_class_test = {}\n",
        "data_class_train = {}\n",
        "data_class_validation = {}\n",
        "\n",
        "for label in MAP_LABEL_TRANSLATION:\n",
        "  if(MAP_LABEL_TRANSLATION[label] not in data_class_test):\n",
        "    data_class_test[MAP_LABEL_TRANSLATION[label]] = []\n",
        "    data_class_validation[MAP_LABEL_TRANSLATION[label]] = []\n",
        "    data_class_train[MAP_LABEL_TRANSLATION[label]] = []\n",
        "\n",
        "for data in data_valid_list:\n",
        "  data_class_validation[MAP_LABEL_TRANSLATION[int(data['label'])]].append(data)\n",
        "for data in data_train_list:\n",
        "  data_class_train[MAP_LABEL_TRANSLATION[int(data['label'])]].append(data)\n",
        "for data in data_test_list:\n",
        "  data_class_test[MAP_LABEL_TRANSLATION[int(data['label'])]].append(data)\n",
        "\n",
        "print('-- Stats for train set --')\n",
        "for label in data_class_train:\n",
        "  print(f'Label {label}: {len(data_class_train[label]):6d}')\n",
        "print('-- Stats for test set --')\n",
        "for label in data_class_test:\n",
        "  print(f'Label {label}: {len(data_class_test[label]):6d}')\n",
        "print('-- Stats for validation set --')\n",
        "for label in data_class_validation:\n",
        "  print(f'Label {label}: {len(data_class_validation[label]):6d}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5N7PYFuKHz-2"
      },
      "outputs": [],
      "source": [
        "   \n",
        "def remove_if_exists(f):\n",
        "    if(Path(f).exists()):\n",
        "        f.unlink()\n",
        "\n",
        "def save_unchanged(f, data):\n",
        "    remove_if_exists(f)\n",
        "    print(f'Saving into: {f}')\n",
        "    with open(f, 'wt') as f_write:\n",
        "        for data_line in data:\n",
        "            data_line_str = json.dumps(data_line)\n",
        "            f_write.write(f'{data_line_str}\\n')\n",
        "\n",
        "def save_as_translations(f, data_classes, num_entries):\n",
        "    file_name = 'translations-' + f.name\n",
        "    file_path = f.parent / file_name\n",
        "    stats = {}\n",
        "    remove_if_exists(Path(file_path))\n",
        "    print(f'Saving into: {file_path}')\n",
        "    \n",
        "    with open(file_path, 'wt') as f_write:\n",
        "        for class_list in data_classes:\n",
        "            if(num_entries > len(data_classes[class_list])):\n",
        "                samples = data_classes[class_list]\n",
        "            else:\n",
        "                samples = random.sample(data_classes[class_list], num_entries)\n",
        "\n",
        "            stats[f'{class_list} entries'] = len(samples)\n",
        "\n",
        "            for data_line in samples:\n",
        "                data_line['label'] = class_list\n",
        "                data_line_str = json.dumps(data_line)\n",
        "                f_write.write(f'{data_line_str}\\n')\n",
        "        print(stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1LayjuGH1ye",
        "outputId": "476a8149-118a-48b4-b7c6-e37e452e27e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving into: data/train.json\n",
            "Saving into: data/translations-train.json\n",
            "{'sadness entries': 1000, 'joy entries': 1000, 'love entries': 1000, 'anger entries': 1000, 'fear entries': 1000, 'suprise entries': 572}\n",
            "Saving into: data/valid.json\n",
            "Saving into: data/translations-valid.json\n",
            "{'sadness entries': 100, 'joy entries': 100, 'love entries': 100, 'anger entries': 100, 'fear entries': 100, 'suprise entries': 81}\n",
            "Saving into: data/test.json\n",
            "Saving into: data/translations-test.json\n",
            "{'sadness entries': 100, 'joy entries': 100, 'love entries': 100, 'anger entries': 100, 'fear entries': 100, 'suprise entries': 66}\n"
          ]
        }
      ],
      "source": [
        "# Rozmiar zbiorÃ³w, podana wartoÅ›Ä‡ to iloÅ›Ä‡ lini dla kaÅ¼degj klasy, jeÅ¼eli dana klasa nie posiada danej iloÅ›ci lini, wszystkie linie zostaja przekazane.\n",
        "def get_num_of_samples(set_name):\n",
        "    if(set_name == 'train'):\n",
        "        return 1000\n",
        "    else:\n",
        "        return 100\n",
        "\n",
        "for file_path, data_to_save, data_classes, num_entries in [ (train_path, data_train_list, data_class_train, get_num_of_samples('train') ), (valid_path, data_valid_list, data_class_validation, get_num_of_samples('valid')), (test_path, data_test_list, data_class_test, get_num_of_samples('test'))]:\n",
        "  save_unchanged(file_path, data_to_save)\n",
        "  save_as_translations(file_path, data_classes, num_entries)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " !wget 'https://raw.githubusercontent.com/huggingface/transformers/v4.12.5/examples/pytorch/text-classification/run_glue_no_trainer.py' -O 'original_run_glue_no_trainer.py'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFL_fQvGkiZG",
        "outputId": "043e975b-5340-4b41-82f0-0d2c6dc922b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-20 19:18:32--  https://raw.githubusercontent.com/huggingface/transformers/v4.12.5/examples/pytorch/text-classification/run_glue_no_trainer.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21091 (21K) [text/plain]\n",
            "Saving to: â€˜original_run_glue_no_trainer.pyâ€™\n",
            "\n",
            "original_run_glue_n 100%[===================>]  20.60K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2022-02-20 19:18:33 (16.6 MB/s) - â€˜original_run_glue_no_trainer.pyâ€™ saved [21091/21091]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pycat original_run_glue_no_trainer.py"
      ],
      "metadata": {
        "id": "-va8TJ7bkrTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python original_run_glue_no_trainer.py --help"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmInBlq0lQ0s",
        "outputId": "f057adfb-5107-44ac-b19b-c0530ec48e3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: original_run_glue_no_trainer.py [-h]\n",
            "                                       [--task_name {cola,mnli,mrpc,qnli,qqp,rte,sst2,stsb,wnli}]\n",
            "                                       [--train_file TRAIN_FILE]\n",
            "                                       [--validation_file VALIDATION_FILE]\n",
            "                                       [--max_length MAX_LENGTH]\n",
            "                                       [--pad_to_max_length]\n",
            "                                       --model_name_or_path MODEL_NAME_OR_PATH\n",
            "                                       [--use_slow_tokenizer]\n",
            "                                       [--per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE]\n",
            "                                       [--per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE]\n",
            "                                       [--learning_rate LEARNING_RATE]\n",
            "                                       [--weight_decay WEIGHT_DECAY]\n",
            "                                       [--num_train_epochs NUM_TRAIN_EPOCHS]\n",
            "                                       [--max_train_steps MAX_TRAIN_STEPS]\n",
            "                                       [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n",
            "                                       [--lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup}]\n",
            "                                       [--num_warmup_steps NUM_WARMUP_STEPS]\n",
            "                                       [--output_dir OUTPUT_DIR] [--seed SEED]\n",
            "                                       [--push_to_hub]\n",
            "                                       [--hub_model_id HUB_MODEL_ID]\n",
            "                                       [--hub_token HUB_TOKEN]\n",
            "\n",
            "Finetune a transformers model on a text classification task\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  --task_name {cola,mnli,mrpc,qnli,qqp,rte,sst2,stsb,wnli}\n",
            "                        The name of the glue task to train on.\n",
            "  --train_file TRAIN_FILE\n",
            "                        A csv or a json file containing the training data.\n",
            "  --validation_file VALIDATION_FILE\n",
            "                        A csv or a json file containing the validation data.\n",
            "  --max_length MAX_LENGTH\n",
            "                        The maximum total input sequence length after\n",
            "                        tokenization. Sequences longer than this will be\n",
            "                        truncated, sequences shorter will be padded if\n",
            "                        `--pad_to_max_lengh` is passed.\n",
            "  --pad_to_max_length   If passed, pad all samples to `max_length`. Otherwise,\n",
            "                        dynamic padding is used.\n",
            "  --model_name_or_path MODEL_NAME_OR_PATH\n",
            "                        Path to pretrained model or model identifier from\n",
            "                        huggingface.co/models.\n",
            "  --use_slow_tokenizer  If passed, will use a slow tokenizer (not backed by\n",
            "                        the ðŸ¤— Tokenizers library).\n",
            "  --per_device_train_batch_size PER_DEVICE_TRAIN_BATCH_SIZE\n",
            "                        Batch size (per device) for the training dataloader.\n",
            "  --per_device_eval_batch_size PER_DEVICE_EVAL_BATCH_SIZE\n",
            "                        Batch size (per device) for the evaluation dataloader.\n",
            "  --learning_rate LEARNING_RATE\n",
            "                        Initial learning rate (after the potential warmup\n",
            "                        period) to use.\n",
            "  --weight_decay WEIGHT_DECAY\n",
            "                        Weight decay to use.\n",
            "  --num_train_epochs NUM_TRAIN_EPOCHS\n",
            "                        Total number of training epochs to perform.\n",
            "  --max_train_steps MAX_TRAIN_STEPS\n",
            "                        Total number of training steps to perform. If\n",
            "                        provided, overrides num_train_epochs.\n",
            "  --gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS\n",
            "                        Number of updates steps to accumulate before\n",
            "                        performing a backward/update pass.\n",
            "  --lr_scheduler_type {linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup}\n",
            "                        The scheduler type to use.\n",
            "  --num_warmup_steps NUM_WARMUP_STEPS\n",
            "                        Number of steps for the warmup in the lr scheduler.\n",
            "  --output_dir OUTPUT_DIR\n",
            "                        Where to store the final model.\n",
            "  --seed SEED           A seed for reproducible training.\n",
            "  --push_to_hub         Whether or not to push the model to the Hub.\n",
            "  --hub_model_id HUB_MODEL_ID\n",
            "                        The name of the repository to keep in sync with the\n",
            "                        local `output_dir`.\n",
            "  --hub_token HUB_TOKEN\n",
            "                        The token to use to push to the Model Hub.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ’» **Enkoder**"
      ],
      "metadata": {
        "id": "ckgYswjfSiqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##RoBERTa"
      ],
      "metadata": {
        "id": "2DcAwTAfTQp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model RoBERTa zostaÅ‚ zaproponowany w ksiÄ…Å¼ce RoBERTa: A Robustly Optimized BERT Pretraining Approach przez Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov. Jest on oparty na modelu BERT firmy Google wydanym w 2018 roku."
      ],
      "metadata": {
        "id": "ItPDhzdwS6QT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kod poniÅ¼ej odnosi siÄ™ do oryginalnego modelu RoBERTa.\n",
        "\n"
      ],
      "metadata": {
        "id": "FwwKKJvydxd7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python run_glue_no_trainer.py \\\n",
        "  --model_name_or_path roberta-base \\\n",
        "  --train_file data/train.json  \\\n",
        "  --validation_file data/valid.json \\\n",
        "  --test_file data/test.json \\\n",
        "  --per_device_train_batch_size 24 \\\n",
        "  --per_device_eval_batch_size 24 \\\n",
        "  --max_length 128 \\\n",
        "  --learning_rate 2e-5 \\\n",
        "  --num_train_epochs 1 \\\n",
        "  --output_dir out/emotion/roberta"
      ],
      "metadata": {
        "id": "hGQkShqcTuOo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b2cbc9b-b65a-444b-ccb4-e2cd620f42da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "02/20/2022 19:44:42 - INFO - __main__ - Distributed environment: NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "Use FP16 precision: False\n",
            "\n",
            "02/20/2022 19:44:43 - WARNING - datasets.builder - Using custom data configuration default-a1b9b28a79015d19\n",
            "02/20/2022 19:44:43 - WARNING - datasets.builder - Reusing dataset json (/root/.cache/huggingface/datasets/json/default-a1b9b28a79015d19/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426)\n",
            "100% 3/3 [00:00<00:00, 875.58it/s]\n",
            "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
            "Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\",\n",
            "    \"5\": \"LABEL_5\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4,\n",
            "    \"LABEL_5\": 5\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
            "Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/d3ccdbfeb9aaa747ef20432d4976c32ee3fa69663b379deb253ccfce2bb1fdc5.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/cafdecc90fcab17011e12ac813dd574b4b3fea39da6dd817813efa010262ff3f.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/d53fc0fa09b8342651efd4073d75e19617b3e51287c2a535becda5808a8db287.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
            "Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "02/20/2022 19:44:51 - INFO - __main__ - Return hidden states from model: False\n",
            "02/20/2022 19:44:51 - INFO - __main__ - Using implementation from: AutoModelForSequenceClassification\n",
            "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "02/20/2022 19:44:53 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-a1b9b28a79015d19/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426/cache-48e99ad75feff5aa.arrow\n",
            "Running tokenizer on dataset: 100% 2/2 [00:00<00:00,  6.55ba/s]\n",
            "02/20/2022 19:44:54 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-a1b9b28a79015d19/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426/cache-1d895d324a0c1082.arrow\n",
            "02/20/2022 19:44:54 - INFO - __main__ - Sample 9647 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [0, 118, 619, 42, 169, 59, 70, 4158, 8728, 33793, 10003, 8, 1441, 992, 11469, 964, 14, 30887, 2], 'labels': 2}.\n",
            "02/20/2022 19:44:54 - INFO - __main__ - Sample 8457 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [0, 757, 2157, 10, 828, 41283, 14, 4356, 608, 10, 346, 9, 209, 383, 416, 3051, 8, 12731, 8973, 3739, 9, 6231, 8, 32065, 8, 1086, 19680, 5190, 544, 358, 28087, 857, 2], 'labels': 1}.\n",
            "02/20/2022 19:44:54 - INFO - __main__ - Sample 2448 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [0, 118, 524, 11, 41, 2888, 16381, 19, 258, 1159, 142, 939, 619, 13856, 2650, 9, 127, 5059, 53, 42, 16, 16529, 2], 'labels': 0}.\n",
            "02/20/2022 19:44:58 - INFO - __main__ - ***** Running training *****\n",
            "02/20/2022 19:44:58 - INFO - __main__ -   Num examples = 16000\n",
            "02/20/2022 19:44:58 - INFO - __main__ -   Num Epochs = 1\n",
            "02/20/2022 19:44:58 - INFO - __main__ -   Instantaneous batch size per device = 24\n",
            "02/20/2022 19:44:58 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 24\n",
            "02/20/2022 19:44:58 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "02/20/2022 19:44:58 - INFO - __main__ -   Total optimization steps = 667\n",
            "100% 667/667 [04:54<00:00,  2.56it/s]02/20/2022 19:50:04 - INFO - __main__ - Epoch 0: {'accuracy': 0.9215}\n",
            "02/20/2022 19:50:17 - INFO - __main__ - Test-set evaluation: {'accuracy': 0.9235}\n",
            "Configuration saved in out/emotion/roberta/config.json\n",
            "Model weights saved in out/emotion/roberta/pytorch_model.bin\n",
            "tokenizer config file saved in out/emotion/roberta/tokenizer_config.json\n",
            "Special tokens file saved in out/emotion/roberta/special_tokens_map.json\n",
            "100% 667/667 [05:20<00:00,  2.08it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kod poniÅ¼ej odnosi siÄ™ do customowego modelu zapisanego w pliku roberta.py. ZwiÄ™kszona zostaÅ‚a liczba epok, a takÅ¼e zmniejszony batchsize na zbiorze treningowym i eval. Dodatkowo zostaÅ‚y zamroÅ¼one wagi (nie w gÅ‚owie klasyfikacji). Learning rate i maksymalna dÅ‚ugoÅ›Ä‡ sekwencji pozostaÅ‚a taka sama."
      ],
      "metadata": {
        "id": "qLEb3Hw-Skv2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python run_glue_no_trainer.py \\\n",
        "  --model_name_or_path roberta-base \\\n",
        "  --train_file data/train.json  \\\n",
        "  --validation_file data/valid.json \\\n",
        "  --test_file data/test.json \\\n",
        "  --per_device_train_batch_size 16 \\\n",
        "  --per_device_eval_batch_size 16 \\\n",
        "  --max_length 128 \\\n",
        "  --freeze_model \\\n",
        "  --learning_rate 2e-5 \\\n",
        "  --num_train_epochs 8 \\\n",
        "  --custom_model \\\n",
        "  --output_dir out/emotion/roberta3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYArs-ufnrMB",
        "outputId": "7d191c0b-0b5a-440a-d95f-2281072ad38c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "02/20/2022 20:28:36 - INFO - __main__ - Distributed environment: NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "Use FP16 precision: False\n",
            "\n",
            "02/20/2022 20:28:37 - WARNING - datasets.builder - Using custom data configuration default-a1b9b28a79015d19\n",
            "02/20/2022 20:28:37 - WARNING - datasets.builder - Reusing dataset json (/root/.cache/huggingface/datasets/json/default-a1b9b28a79015d19/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426)\n",
            "100% 3/3 [00:00<00:00, 895.64it/s]\n",
            "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
            "Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\",\n",
            "    \"5\": \"LABEL_5\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4,\n",
            "    \"LABEL_5\": 5\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
            "Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/d3ccdbfeb9aaa747ef20432d4976c32ee3fa69663b379deb253ccfce2bb1fdc5.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/cafdecc90fcab17011e12ac813dd574b4b3fea39da6dd817813efa010262ff3f.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/d53fc0fa09b8342651efd4073d75e19617b3e51287c2a535becda5808a8db287.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
            "Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "02/20/2022 20:28:45 - INFO - __main__ - Return hidden states from model: False\n",
            "02/20/2022 20:28:45 - INFO - __main__ - Using implementation from: RobertaForSequenceClassificationCustom\n",
            "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassificationCustom: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'roberta.pooler.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassificationCustom from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassificationCustom from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassificationCustom were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense_2.bias', 'classifier.out_proj.bias', 'classifier.dense_1.weight', 'classifier.dense_1.bias', 'classifier.dense_2.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "02/20/2022 20:28:49 - INFO - __main__ - Freezing model weights\n",
            "Running tokenizer on dataset: 100% 16/16 [00:01<00:00, 13.44ba/s]\n",
            "Running tokenizer on dataset: 100% 2/2 [00:00<00:00, 15.30ba/s]\n",
            "Running tokenizer on dataset: 100% 2/2 [00:00<00:00, 17.29ba/s]\n",
            "02/20/2022 20:28:50 - INFO - __main__ - Sample 10032 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [0, 118, 1415, 23, 11992, 24248, 5, 1855, 35783, 652, 2157, 182, 18452, 393, 465, 23184, 142, 89, 16, 117, 7731, 2], 'labels': 1}.\n",
            "02/20/2022 20:28:50 - INFO - __main__ - Sample 12496 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [0, 118, 33, 393, 1145, 11, 588, 301, 53, 619, 2422, 30126, 7, 149, 1486, 28303, 8, 16333, 408, 8, 127, 92, 1441, 579, 1742, 23, 10, 48225, 2054, 358, 428, 7915, 13247, 3006, 21210, 2], 'labels': 1}.\n",
            "02/20/2022 20:28:50 - INFO - __main__ - Sample 6222 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [0, 118, 619, 101, 449, 9475, 16, 145, 444, 350, 34405, 1920, 219, 5783, 15, 70, 18958, 2], 'labels': 3}.\n",
            "02/20/2022 20:28:54 - INFO - __main__ - ***** Running training *****\n",
            "02/20/2022 20:28:54 - INFO - __main__ -   Num examples = 16000\n",
            "02/20/2022 20:28:54 - INFO - __main__ -   Num Epochs = 8\n",
            "02/20/2022 20:28:54 - INFO - __main__ -   Instantaneous batch size per device = 16\n",
            "02/20/2022 20:28:54 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "02/20/2022 20:28:54 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "02/20/2022 20:28:54 - INFO - __main__ -   Total optimization steps = 8000\n",
            " 12% 999/8000 [01:36<12:21,  9.44it/s]02/20/2022 20:30:43 - INFO - __main__ - Epoch 0: {'accuracy': 0.3525}\n",
            " 25% 2000/8000 [03:25<09:32, 10.48it/s]02/20/2022 20:32:32 - INFO - __main__ - Epoch 1: {'accuracy': 0.397}\n",
            " 38% 3000/8000 [05:15<08:30,  9.80it/s]02/20/2022 20:34:22 - INFO - __main__ - Epoch 2: {'accuracy': 0.3615}\n",
            " 50% 4000/8000 [07:04<06:02, 11.03it/s]02/20/2022 20:36:11 - INFO - __main__ - Epoch 3: {'accuracy': 0.467}\n",
            " 62% 4999/8000 [08:53<04:51, 10.31it/s]02/20/2022 20:38:00 - INFO - __main__ - Epoch 4: {'accuracy': 0.502}\n",
            " 75% 6000/8000 [10:43<03:18, 10.06it/s]02/20/2022 20:39:50 - INFO - __main__ - Epoch 5: {'accuracy': 0.515}\n",
            " 87% 6999/8000 [12:32<01:37, 10.27it/s]02/20/2022 20:41:39 - INFO - __main__ - Epoch 6: {'accuracy': 0.516}\n",
            "100% 8000/8000 [14:32<00:00, 11.17it/s]02/20/2022 20:43:28 - INFO - __main__ - Epoch 7: {'accuracy': 0.5155}\n",
            "02/20/2022 20:43:40 - INFO - __main__ - Test-set evaluation: {'accuracy': 0.5195}\n",
            "Configuration saved in out/emotion/roberta3/config.json\n",
            "Model weights saved in out/emotion/roberta3/pytorch_model.bin\n",
            "tokenizer config file saved in out/emotion/roberta3/tokenizer_config.json\n",
            "Special tokens file saved in out/emotion/roberta3/special_tokens_map.json\n",
            "100% 8000/8000 [14:47<00:00,  9.02it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kod poniÅ¼ej odnosi siÄ™ do pliku robertaforward.py. Batch zostaÅ‚ zmniejszony do 12, maksymalna dÅ‚ugoÅ›Ä‡ sekwencji (max_length) zostaje taka sama. Dodatkowo, dodany zostaÅ‚ pooling layer. Wagi (nie w gÅ‚owie klasyfikacji) zostaÅ‚y zamroÅ¼one. Model byÅ‚ trenowany w 12 epokach."
      ],
      "metadata": {
        "id": "7JRjgei6XWXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python run_glue_no_trainer2.py \\\n",
        "  --model_name_or_path roberta-base \\\n",
        "  --train_file data/train.json  \\\n",
        "  --validation_file data/valid.json \\\n",
        "  --test_file data/test.json \\\n",
        "  --per_device_train_batch_size 12 \\\n",
        "  --per_device_eval_batch_size 12 \\\n",
        "  --max_length 128 \\\n",
        "  --freeze_model \\\n",
        "  --learning_rate 2e-5 \\\n",
        "  --num_train_epochs 12 \\\n",
        "  --custom_model \\\n",
        "  --output_dir out/emotion/roberta4\n",
        "   \n",
        "  # --lr_scheduler_type \"linear\" \\\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7hX7c-J2J6t",
        "outputId": "921db42a-36ce-4a61-a332-e16442c984e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "02/20/2022 21:01:01 - INFO - __main__ - Distributed environment: NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "Use FP16 precision: False\n",
            "\n",
            "02/20/2022 21:01:01 - WARNING - datasets.builder - Using custom data configuration default-a1b9b28a79015d19\n",
            "02/20/2022 21:01:01 - WARNING - datasets.builder - Reusing dataset json (/root/.cache/huggingface/datasets/json/default-a1b9b28a79015d19/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426)\n",
            "100% 3/3 [00:00<00:00, 834.69it/s]\n",
            "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
            "Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\",\n",
            "    \"5\": \"LABEL_5\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4,\n",
            "    \"LABEL_5\": 5\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
            "Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/d3ccdbfeb9aaa747ef20432d4976c32ee3fa69663b379deb253ccfce2bb1fdc5.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/cafdecc90fcab17011e12ac813dd574b4b3fea39da6dd817813efa010262ff3f.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/d53fc0fa09b8342651efd4073d75e19617b3e51287c2a535becda5808a8db287.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
            "Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "02/20/2022 21:01:10 - INFO - __main__ - Return hidden states from model: False\n",
            "02/20/2022 21:01:10 - INFO - __main__ - Using implementation from: RobertaForSequenceClassificationCustomAlternative\n",
            "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassificationCustomAlternative: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassificationCustomAlternative from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassificationCustomAlternative from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassificationCustomAlternative were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense_1_hidden.bias', 'classifier.dense_1_hidden.weight', 'classifier.dense_1_input.weight', 'classifier.dense_1_input.bias', 'classifier.dense_2.bias', 'classifier.out_proj.bias', 'classifier.dense_2.weight', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "02/20/2022 21:01:13 - INFO - __main__ - Freezing model weights\n",
            "Running tokenizer on dataset: 100% 16/16 [00:01<00:00, 13.35ba/s]\n",
            "Running tokenizer on dataset: 100% 2/2 [00:00<00:00, 17.64ba/s]\n",
            "Running tokenizer on dataset: 100% 2/2 [00:00<00:00, 17.62ba/s]\n",
            "02/20/2022 21:01:15 - INFO - __main__ - Sample 7141 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [0, 118, 40, 2662, 89, 13, 10, 353, 150, 4066, 8, 512, 1168, 213, 184, 13, 29224, 13738, 30, 5, 169, 51, 222, 45, 342, 143, 4666, 15, 162, 42, 76, 939, 524, 45, 2157, 182, 12298, 235, 122, 2], 'labels': 1}.\n",
            "02/20/2022 21:01:15 - INFO - __main__ - Sample 10092 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [0, 118, 1034, 7, 146, 1925, 3741, 5992, 619, 33552, 11, 127, 809, 11, 143, 169, 678, 25, 65, 9, 127, 92, 107, 13781, 2], 'labels': 0}.\n",
            "02/20/2022 21:01:15 - INFO - __main__ - Sample 8933 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [0, 118, 524, 2157, 15828, 59, 127, 695, 2], 'labels': 1}.\n",
            "02/20/2022 21:01:19 - INFO - __main__ - ***** Running training *****\n",
            "02/20/2022 21:01:19 - INFO - __main__ -   Num examples = 16000\n",
            "02/20/2022 21:01:19 - INFO - __main__ -   Num Epochs = 12\n",
            "02/20/2022 21:01:19 - INFO - __main__ -   Instantaneous batch size per device = 12\n",
            "02/20/2022 21:01:19 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 12\n",
            "02/20/2022 21:01:19 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "02/20/2022 21:01:19 - INFO - __main__ -   Total optimization steps = 16008\n",
            "  8% 1333/16008 [01:46<20:05, 12.18it/s]02/20/2022 21:03:18 - INFO - __main__ - Epoch 0: {'accuracy': 0.352}\n",
            " 17% 2667/16008 [03:45<17:23, 12.78it/s]02/20/2022 21:05:18 - INFO - __main__ - Epoch 1: {'accuracy': 0.395}\n",
            " 25% 4001/16008 [05:45<16:30, 12.12it/s]02/20/2022 21:07:18 - INFO - __main__ - Epoch 2: {'accuracy': 0.322}\n",
            " 33% 5335/16008 [07:45<14:17, 12.45it/s]02/20/2022 21:09:18 - INFO - __main__ - Epoch 3: {'accuracy': 0.352}\n",
            " 42% 6669/16008 [09:45<11:31, 13.50it/s]02/20/2022 21:11:17 - INFO - __main__ - Epoch 4: {'accuracy': 0.511}\n",
            " 50% 8003/16008 [11:45<10:20, 12.89it/s]02/20/2022 21:13:17 - INFO - __main__ - Epoch 5: {'accuracy': 0.352}\n",
            " 58% 9337/16008 [13:44<08:42, 12.77it/s]02/20/2022 21:15:17 - INFO - __main__ - Epoch 6: {'accuracy': 0.352}\n",
            " 67% 10671/16008 [15:44<07:11, 12.38it/s]02/20/2022 21:17:17 - INFO - __main__ - Epoch 7: {'accuracy': 0.514}\n",
            " 75% 12005/16008 [17:44<05:30, 12.12it/s]02/20/2022 21:19:16 - INFO - __main__ - Epoch 8: {'accuracy': 0.352}\n",
            " 83% 13339/16008 [19:43<03:29, 12.75it/s]02/20/2022 21:21:16 - INFO - __main__ - Epoch 9: {'accuracy': 0.352}\n",
            " 92% 14673/16008 [21:43<01:46, 12.53it/s]02/20/2022 21:23:15 - INFO - __main__ - Epoch 10: {'accuracy': 0.352}\n",
            "100% 16007/16008 [23:42<00:00, 12.18it/s]02/20/2022 21:25:15 - INFO - __main__ - Epoch 11: {'accuracy': 0.352}\n",
            "100% 16008/16008 [24:02<00:00, 12.18it/s]02/20/2022 21:25:27 - INFO - __main__ - Test-set evaluation: {'accuracy': 0.3475}\n",
            "Configuration saved in out/emotion/roberta4/config.json\n",
            "Model weights saved in out/emotion/roberta4/pytorch_model.bin\n",
            "tokenizer config file saved in out/emotion/roberta4/tokenizer_config.json\n",
            "Special tokens file saved in out/emotion/roberta4/special_tokens_map.json\n",
            "100% 16008/16008 [24:10<00:00, 11.04it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kod poniÅ¼ej odnosi siÄ™ do pliku robertasmallhead.py. Batchsize zostaÅ‚ zwiÄ™kszony do 32, dodatkowo learning rate zostaÅ‚ zmieniony na 3*10^-5."
      ],
      "metadata": {
        "id": "GqD04vCFckJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python run_glue_no_trainer3.py \\\n",
        "  --model_name_or_path roberta-base \\\n",
        "  --train_file data/train.json  \\\n",
        "  --validation_file data/valid.json \\\n",
        "  --test_file data/test.json \\\n",
        "  --per_device_train_batch_size 32 \\\n",
        "  --per_device_eval_batch_size 32 \\\n",
        "  --max_length 128 \\\n",
        "  --freeze_model \\\n",
        "  --learning_rate 3e-5 \\\n",
        "  --num_train_epochs 12 \\\n",
        "  --custom_model \\\n",
        "  --output_dir out/emotion/roberta5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfh8Cv_6-9Ch",
        "outputId": "db0a719f-9b1d-421b-a8a8-c0303b29387d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "02/20/2022 22:03:06 - INFO - __main__ - Distributed environment: NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "Use FP16 precision: False\n",
            "\n",
            "02/20/2022 22:03:07 - WARNING - datasets.builder - Using custom data configuration default-a1b9b28a79015d19\n",
            "02/20/2022 22:03:07 - WARNING - datasets.builder - Reusing dataset json (/root/.cache/huggingface/datasets/json/default-a1b9b28a79015d19/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426)\n",
            "100% 3/3 [00:00<00:00, 749.88it/s]\n",
            "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
            "Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\",\n",
            "    \"5\": \"LABEL_5\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4,\n",
            "    \"LABEL_5\": 5\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
            "Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/d3ccdbfeb9aaa747ef20432d4976c32ee3fa69663b379deb253ccfce2bb1fdc5.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/cafdecc90fcab17011e12ac813dd574b4b3fea39da6dd817813efa010262ff3f.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/d53fc0fa09b8342651efd4073d75e19617b3e51287c2a535becda5808a8db287.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
            "Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "02/20/2022 22:03:15 - INFO - __main__ - Return hidden states from model: False\n",
            "02/20/2022 22:03:15 - INFO - __main__ - Using implementation from: RobertaForSequenceClassificationCustomAlternative\n",
            "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassificationCustomAlternative: ['roberta.pooler.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassificationCustomAlternative from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassificationCustomAlternative from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassificationCustomAlternative were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense_1_input.bias', 'classifier.out_proj.bias', 'classifier.dense_1_hidden.weight', 'classifier.dense_1_input.weight', 'classifier.dense_2.weight', 'classifier.out_proj.weight', 'classifier.dense_1_hidden.bias', 'classifier.dense_2.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "02/20/2022 22:03:19 - INFO - __main__ - Freezing model weights\n",
            "02/20/2022 22:03:19 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-a1b9b28a79015d19/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426/cache-9df18f7c1b70f5f5.arrow\n",
            "02/20/2022 22:03:19 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-a1b9b28a79015d19/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426/cache-0ddc9665f56b7c4e.arrow\n",
            "02/20/2022 22:03:19 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-a1b9b28a79015d19/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426/cache-d6dacb9b2409a6f3.arrow\n",
            "02/20/2022 22:03:19 - INFO - __main__ - Sample 11799 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [0, 118, 619, 16962, 7, 33, 5360, 54, 1346, 8, 40, 14518, 24, 88, 49, 2414, 2], 'labels': 1}.\n",
            "02/20/2022 22:03:19 - INFO - __main__ - Sample 3646 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [0, 118, 531, 23721, 4356, 2157, 10, 410, 13203, 2], 'labels': 4}.\n",
            "02/20/2022 22:03:19 - INFO - __main__ - Sample 15287 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [0, 118, 619, 2051, 37, 3639, 19, 10, 4520, 6675, 2], 'labels': 1}.\n",
            "02/20/2022 22:03:23 - INFO - __main__ - ***** Running training *****\n",
            "02/20/2022 22:03:23 - INFO - __main__ -   Num examples = 16000\n",
            "02/20/2022 22:03:23 - INFO - __main__ -   Num Epochs = 12\n",
            "02/20/2022 22:03:23 - INFO - __main__ -   Instantaneous batch size per device = 32\n",
            "02/20/2022 22:03:23 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "02/20/2022 22:03:23 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "02/20/2022 22:03:23 - INFO - __main__ -   Total optimization steps = 6000\n",
            "  8% 500/6000 [01:38<17:56,  5.11it/s]02/20/2022 22:05:14 - INFO - __main__ - Epoch 0: {'accuracy': 0.352}\n",
            " 17% 1000/6000 [03:30<16:50,  4.95it/s]02/20/2022 22:07:06 - INFO - __main__ - Epoch 1: {'accuracy': 0.389}\n",
            " 25% 1500/6000 [05:22<14:53,  5.04it/s]02/20/2022 22:08:58 - INFO - __main__ - Epoch 2: {'accuracy': 0.4715}\n",
            " 33% 2000/6000 [07:14<12:45,  5.22it/s]02/20/2022 22:10:50 - INFO - __main__ - Epoch 3: {'accuracy': 0.4905}\n",
            " 42% 2500/6000 [09:05<13:15,  4.40it/s]02/20/2022 22:12:42 - INFO - __main__ - Epoch 4: {'accuracy': 0.512}\n",
            " 50% 3000/6000 [10:57<08:58,  5.57it/s]02/20/2022 22:14:33 - INFO - __main__ - Epoch 5: {'accuracy': 0.5}\n",
            " 58% 3500/6000 [12:49<08:34,  4.86it/s]02/20/2022 22:16:25 - INFO - __main__ - Epoch 6: {'accuracy': 0.5135}\n",
            " 67% 4000/6000 [14:41<06:16,  5.32it/s]02/20/2022 22:18:17 - INFO - __main__ - Epoch 7: {'accuracy': 0.5205}\n",
            " 75% 4500/6000 [16:32<04:41,  5.33it/s]02/20/2022 22:20:08 - INFO - __main__ - Epoch 8: {'accuracy': 0.517}\n",
            " 83% 5000/6000 [18:24<03:15,  5.10it/s]02/20/2022 22:22:00 - INFO - __main__ - Epoch 9: {'accuracy': 0.522}\n",
            " 92% 5500/6000 [20:16<01:45,  4.73it/s]02/20/2022 22:23:52 - INFO - __main__ - Epoch 10: {'accuracy': 0.523}\n",
            "100% 6000/6000 [22:08<00:00,  4.73it/s]02/20/2022 22:25:44 - INFO - __main__ - Epoch 11: {'accuracy': 0.5215}\n",
            "02/20/2022 22:25:56 - INFO - __main__ - Test-set evaluation: {'accuracy': 0.5275}\n",
            "Configuration saved in out/emotion/roberta5/config.json\n",
            "Model weights saved in out/emotion/roberta5/pytorch_model.bin\n",
            "tokenizer config file saved in out/emotion/roberta5/tokenizer_config.json\n",
            "Special tokens file saved in out/emotion/roberta5/special_tokens_map.json\n",
            "100% 6000/6000 [22:34<00:00,  4.43it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kod poniÅ¼ej opiera siÄ™ o plik roberta.py. Zmieniona zostaÅ‚a liczba epok, batch size i learning rate. UÅ¼yte zostaÅ‚y hidden states."
      ],
      "metadata": {
        "id": "fvIFv8rGaGuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python run_glue_no_trainer.py \\\n",
        "  --model_name_or_path roberta-base \\\n",
        "  --train_file data/train.json  \\\n",
        "  --validation_file data/valid.json \\\n",
        "  --test_file data/test.json \\\n",
        "  --per_device_train_batch_size 26 \\\n",
        "  --per_device_eval_batch_size 26 \\\n",
        "  --max_length 128 \\\n",
        "  --return_hidden_states \\\n",
        "  --learning_rate 2e-7 \\\n",
        "  --num_train_epochs 8 \\\n",
        "  --custom_model \\\n",
        "  --output_dir out/emotion/roberta6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9CkKb7BUJPM",
        "outputId": "42a4ad5f-9ba3-4367-9884-90275c74e175"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "02/20/2022 22:47:13 - INFO - __main__ - Distributed environment: NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "Use FP16 precision: False\n",
            "\n",
            "02/20/2022 22:47:14 - WARNING - datasets.builder - Using custom data configuration default-a1b9b28a79015d19\n",
            "02/20/2022 22:47:14 - WARNING - datasets.builder - Reusing dataset json (/root/.cache/huggingface/datasets/json/default-a1b9b28a79015d19/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426)\n",
            "100% 3/3 [00:00<00:00, 871.39it/s]\n",
            "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
            "Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\",\n",
            "    \"5\": \"LABEL_5\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4,\n",
            "    \"LABEL_5\": 5\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
            "Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/d3ccdbfeb9aaa747ef20432d4976c32ee3fa69663b379deb253ccfce2bb1fdc5.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/cafdecc90fcab17011e12ac813dd574b4b3fea39da6dd817813efa010262ff3f.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/d53fc0fa09b8342651efd4073d75e19617b3e51287c2a535becda5808a8db287.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
            "Model config RobertaConfig {\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "02/20/2022 22:47:23 - INFO - __main__ - Return hidden states from model: True\n",
            "02/20/2022 22:47:23 - INFO - __main__ - Using implementation from: RobertaForSequenceClassificationCustom\n",
            "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassificationCustom: ['lm_head.dense.weight', 'lm_head.bias', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassificationCustom from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassificationCustom from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassificationCustom were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense_1.bias', 'classifier.out_proj.weight', 'classifier.dense_2.weight', 'classifier.dense_1.weight', 'classifier.dense_2.bias', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Running tokenizer on dataset: 100% 16/16 [00:01<00:00, 15.42ba/s]\n",
            "Running tokenizer on dataset: 100% 2/2 [00:00<00:00, 18.76ba/s]\n",
            "Running tokenizer on dataset: 100% 2/2 [00:00<00:00, 19.26ba/s]\n",
            "02/20/2022 22:47:28 - INFO - __main__ - Sample 5971 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [0, 118, 619, 17319, 600, 206, 269, 1275, 2713, 19, 10473, 3947, 53, 939, 619, 939, 240, 7, 109, 42, 7, 357, 2185, 25, 41, 3025, 2], 'labels': 0}.\n",
            "02/20/2022 22:47:28 - INFO - __main__ - Sample 7709 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [0, 118, 619, 14, 43011, 14459, 162, 142, 939, 218, 326, 216, 5, 3099, 9, 1383, 1757, 48599, 47215, 2054, 1662, 2], 'labels': 0}.\n",
            "02/20/2022 22:47:28 - INFO - __main__ - Sample 7806 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [0, 118, 373, 41, 9452, 298, 174, 123, 127, 6453, 37, 21, 182, 8440, 2], 'labels': 2}.\n",
            "02/20/2022 22:47:32 - INFO - __main__ - ***** Running training *****\n",
            "02/20/2022 22:47:32 - INFO - __main__ -   Num examples = 16000\n",
            "02/20/2022 22:47:32 - INFO - __main__ -   Num Epochs = 8\n",
            "02/20/2022 22:47:32 - INFO - __main__ -   Instantaneous batch size per device = 26\n",
            "02/20/2022 22:47:32 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 26\n",
            "02/20/2022 22:47:32 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "02/20/2022 22:47:32 - INFO - __main__ -   Total optimization steps = 4928\n",
            " 12% 616/4928 [04:55<29:23,  2.44it/s]02/20/2022 22:52:40 - INFO - __main__ - Epoch 0: {'accuracy': 0.352}\n",
            " 25% 1232/4928 [10:06<25:48,  2.39it/s]02/20/2022 22:57:50 - INFO - __main__ - Epoch 1: {'accuracy': 0.352}\n",
            " 38% 1848/4928 [15:15<20:50,  2.46it/s]02/20/2022 23:03:00 - INFO - __main__ - Epoch 2: {'accuracy': 0.4425}\n",
            " 50% 2464/4928 [20:24<17:08,  2.40it/s]02/20/2022 23:08:09 - INFO - __main__ - Epoch 3: {'accuracy': 0.5585}\n",
            " 62% 3080/4928 [25:35<12:15,  2.51it/s]02/20/2022 23:13:20 - INFO - __main__ - Epoch 4: {'accuracy': 0.565}\n",
            " 75% 3696/4928 [30:45<08:17,  2.48it/s]02/20/2022 23:18:29 - INFO - __main__ - Epoch 5: {'accuracy': 0.566}\n",
            " 88% 4312/4928 [35:55<04:28,  2.29it/s]02/20/2022 23:23:40 - INFO - __main__ - Epoch 6: {'accuracy': 0.5665}\n",
            "100% 4928/4928 [41:05<00:00,  2.51it/s]02/20/2022 23:28:50 - INFO - __main__ - Epoch 7: {'accuracy': 0.5655}\n",
            "02/20/2022 23:29:02 - INFO - __main__ - Test-set evaluation: {'accuracy': 0.5895}\n",
            "Configuration saved in out/emotion/roberta6/config.json\n",
            "Model weights saved in out/emotion/roberta6/pytorch_model.bin\n",
            "tokenizer config file saved in out/emotion/roberta6/tokenizer_config.json\n",
            "Special tokens file saved in out/emotion/roberta6/special_tokens_map.json\n",
            "100% 4928/4928 [41:32<00:00,  1.98it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ewaluacja "
      ],
      "metadata": {
        "id": "n09w_5aagzYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_glue.py \\\n",
        "--model_name_or_path out/emotion/roberta \\\n",
        "--output_dir out/emotion/roberta-eval \\\n",
        "--return_hidden_states --custom_model \\\n",
        "--train_file data/train.json --validation_file data/valid.json \\\n",
        "--do_eval \\\n",
        "--per_device_eval_batch_size 24 --max_seq_length 128 \\\n",
        "--return_hidden_states --custom_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2E9LUcfLg1qg",
        "outputId": "492a7afc-8cc0-46b1-974b-31108afa6897"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "02/20/2022 23:43:12 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "02/20/2022 23:43:12 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_find_unused_parameters=None,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_steps=None,\n",
            "evaluation_strategy=IntervalStrategy.NO,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "hub_model_id=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=-1,\n",
            "log_level_replica=-1,\n",
            "log_on_each_node=True,\n",
            "logging_dir=out/emotion/roberta-eval/runs/Feb20_23-43-12_797cce3b4088,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "output_dir=out/emotion/roberta-eval,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=24,\n",
            "per_device_train_batch_size=8,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=out/emotion/roberta-eval,\n",
            "save_on_each_node=False,\n",
            "save_steps=500,\n",
            "save_strategy=IntervalStrategy.STEPS,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_legacy_prediction_loop=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "02/20/2022 23:43:12 - INFO - __main__ - load a local file for train: data/train.json\n",
            "02/20/2022 23:43:12 - INFO - __main__ - load a local file for validation: data/valid.json\n",
            "02/20/2022 23:43:13 - WARNING - datasets.builder - Using custom data configuration default-03b762c1f7f9a605\n",
            "02/20/2022 23:43:13 - INFO - datasets.builder - Generating dataset json (/root/.cache/huggingface/datasets/json/default-03b762c1f7f9a605/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426)\n",
            "Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-03b762c1f7f9a605/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426...\n",
            "100% 2/2 [00:00<00:00, 6904.20it/s]\n",
            "02/20/2022 23:43:13 - INFO - datasets.utils.download_manager - Downloading took 0.0 min\n",
            "02/20/2022 23:43:13 - INFO - datasets.utils.download_manager - Checksum Computation took 0.0 min\n",
            "100% 2/2 [00:00<00:00, 1182.66it/s]\n",
            "02/20/2022 23:43:13 - INFO - datasets.utils.info_utils - Unable to verify checksums.\n",
            "02/20/2022 23:43:13 - INFO - datasets.builder - Generating split train\n",
            "02/20/2022 23:43:13 - INFO - datasets.builder - Generating split validation\n",
            "02/20/2022 23:43:13 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-03b762c1f7f9a605/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426. Subsequent calls will reuse this data.\n",
            "100% 2/2 [00:00<00:00, 938.74it/s]\n",
            "[INFO|configuration_utils.py:586] 2022-02-20 23:43:13,550 >> loading configuration file out/emotion/roberta/config.json\n",
            "[INFO|configuration_utils.py:625] 2022-02-20 23:43:13,551 >> Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"roberta-base\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": 0,\n",
            "    \"1\": 1,\n",
            "    \"2\": 2,\n",
            "    \"3\": 3,\n",
            "    \"4\": 4,\n",
            "    \"5\": 5\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"0\": 0,\n",
            "    \"1\": 1,\n",
            "    \"2\": 2,\n",
            "    \"3\": 3,\n",
            "    \"4\": 4,\n",
            "    \"5\": 5\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:1671] 2022-02-20 23:43:13,553 >> Didn't find file out/emotion/roberta/added_tokens.json. We won't load it.\n",
            "[INFO|tokenization_utils_base.py:1740] 2022-02-20 23:43:13,553 >> loading file out/emotion/roberta/vocab.json\n",
            "[INFO|tokenization_utils_base.py:1740] 2022-02-20 23:43:13,553 >> loading file out/emotion/roberta/merges.txt\n",
            "[INFO|tokenization_utils_base.py:1740] 2022-02-20 23:43:13,553 >> loading file out/emotion/roberta/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:1740] 2022-02-20 23:43:13,553 >> loading file None\n",
            "[INFO|tokenization_utils_base.py:1740] 2022-02-20 23:43:13,553 >> loading file out/emotion/roberta/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:1740] 2022-02-20 23:43:13,553 >> loading file out/emotion/roberta/tokenizer_config.json\n",
            "02/20/2022 23:43:13 - INFO - __main__ - Return hidden states from model: True\n",
            "Traceback (most recent call last):\n",
            "  File \"run_glue.py\", line 611, in <module>\n",
            "    main()\n",
            "  File \"run_glue.py\", line 357, in main\n",
            "    model_cls = RobertaForSequenceClassificationCustomAlternative\n",
            "NameError: name 'RobertaForSequenceClassificationCustomAlternative' is not defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ”‰ Seq2seq"
      ],
      "metadata": {
        "id": "pNxn6aEXdCiw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### T5"
      ],
      "metadata": {
        "id": "j6p_6fG9dYRL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "etaWlXFIdS6C"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "emotion-detection-roberta.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dae071c03da549cdad7eb0b59d85d87a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_51724145c0df4dcb88b36d597982705a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3047d03eef75427bbaafd1d7b2a6f8a5",
              "IPY_MODEL_5f89aaa1c32148539cd148a91b52a8d5",
              "IPY_MODEL_2e394268cdc74f75aee9f572106e2a6e"
            ]
          }
        },
        "51724145c0df4dcb88b36d597982705a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3047d03eef75427bbaafd1d7b2a6f8a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e7a3526ae0c047b296591c2cd4c9139e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: ",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7327fcb2e766421a837515e61a06880d"
          }
        },
        "5f89aaa1c32148539cd148a91b52a8d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_42f489c532b04b53b09bfdaf40bbf35a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1655,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1655,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4751a4c2a47c4b7794f5700f8e5fbfa3"
          }
        },
        "2e394268cdc74f75aee9f572106e2a6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e21b950052064bad8eda00c73e0d9ea6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3.62k/? [00:00&lt;00:00, 86.4kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_992804019c024d0f9cbf9aa64b25a235"
          }
        },
        "e7a3526ae0c047b296591c2cd4c9139e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7327fcb2e766421a837515e61a06880d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "42f489c532b04b53b09bfdaf40bbf35a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4751a4c2a47c4b7794f5700f8e5fbfa3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e21b950052064bad8eda00c73e0d9ea6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "992804019c024d0f9cbf9aa64b25a235": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1f348c3b23994ec181d45de43dd1ef5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_032ed4e2d9fe4510b5a6a02c569e934d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_388603f7569e4be6966b73e8fa45d6cb",
              "IPY_MODEL_fcd5ae574a7b4801b4050d73ae519488",
              "IPY_MODEL_48bb0ef27dc9410cb8265cfba6464f38"
            ]
          }
        },
        "032ed4e2d9fe4510b5a6a02c569e934d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "388603f7569e4be6966b73e8fa45d6cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fd399a6c439f4f9d8eb26000ca9e1e1d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: ",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f0db8e5f4852445d94251854018937df"
          }
        },
        "fcd5ae574a7b4801b4050d73ae519488": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_85d7a510ee2046f2bdff9d49d850df64",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1611,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1611,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bb9632d2d59a401fa7fcc2887da1914a"
          }
        },
        "48bb0ef27dc9410cb8265cfba6464f38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f5762e87b3c941feb913ccc1d421d8c2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3.28k/? [00:00&lt;00:00, 89.8kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4e10b8a643214c0dabe346269bc40efe"
          }
        },
        "fd399a6c439f4f9d8eb26000ca9e1e1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f0db8e5f4852445d94251854018937df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "85d7a510ee2046f2bdff9d49d850df64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bb9632d2d59a401fa7fcc2887da1914a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f5762e87b3c941feb913ccc1d421d8c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4e10b8a643214c0dabe346269bc40efe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d73c7b25315045f6835bdd06c4b8a3ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cba05fb4da6340b485d772a03bf81a43",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e19affe8ca5045df8cdeee8de2844494",
              "IPY_MODEL_60af17e9f117434fb1d5573e09ae40d3",
              "IPY_MODEL_d06ec525ea3249c1b59f73cbc40dbe24"
            ]
          }
        },
        "cba05fb4da6340b485d772a03bf81a43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e19affe8ca5045df8cdeee8de2844494": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e16bae913b384ebaac18366a74906a71",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: ",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_710a31601ca543bea660c245757954f4"
          }
        },
        "60af17e9f117434fb1d5573e09ae40d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e8fca2fc409d4b6bb814db712c4fbc0a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3ddced4524cb4ea4a9553f1feb11564e"
          }
        },
        "d06ec525ea3249c1b59f73cbc40dbe24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9a756c46d63149cba8eadf4aec23eb0d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.66M/? [00:00&lt;00:00, 4.30MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1d61d3ebd3be431b9faec1dc56d2c0a4"
          }
        },
        "e16bae913b384ebaac18366a74906a71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "710a31601ca543bea660c245757954f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e8fca2fc409d4b6bb814db712c4fbc0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3ddced4524cb4ea4a9553f1feb11564e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9a756c46d63149cba8eadf4aec23eb0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1d61d3ebd3be431b9faec1dc56d2c0a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "945ec2317df14cd0a54c14ca03e59313": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_647be445b75b437597bcf0eb280685cd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2d0b3e7a7ca7436cb6d826aaffd01bf0",
              "IPY_MODEL_221fe854e4684588a2e86eff6a4593fd",
              "IPY_MODEL_4fd9e34b65944ef9b9ba1cc12e2ce010"
            ]
          }
        },
        "647be445b75b437597bcf0eb280685cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2d0b3e7a7ca7436cb6d826aaffd01bf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e809d345a5064f0c9c83c18caa3b825b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: ",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ef80d22b78a649e8bfddfe4feb9f7ad1"
          }
        },
        "221fe854e4684588a2e86eff6a4593fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d95add2193a24c92b376f203fb380815",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6ba72b3a60ac40dba071a1638a468f48"
          }
        },
        "4fd9e34b65944ef9b9ba1cc12e2ce010": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c30221309ca341d1a2fe10063aa75af8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 204k/? [00:00&lt;00:00, 741kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f26e26c72bc74b5689160d7ef477beac"
          }
        },
        "e809d345a5064f0c9c83c18caa3b825b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ef80d22b78a649e8bfddfe4feb9f7ad1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d95add2193a24c92b376f203fb380815": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6ba72b3a60ac40dba071a1638a468f48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c30221309ca341d1a2fe10063aa75af8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f26e26c72bc74b5689160d7ef477beac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0b9467ed14394c908ff311dff73ba85d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c7a0ee7eac074ee3a2c0db67d04ee0a0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_43663f128ea34aaab9fac9d78b76a28d",
              "IPY_MODEL_446af72edb2847d89645b505f062b470",
              "IPY_MODEL_a27d29f0a19b484ba0f6f495992dcefa"
            ]
          }
        },
        "c7a0ee7eac074ee3a2c0db67d04ee0a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "43663f128ea34aaab9fac9d78b76a28d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_aaa0b25715664424868ec42a64d70781",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: ",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9bc6adc93c144357898953a96850e892"
          }
        },
        "446af72edb2847d89645b505f062b470": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_78a19f22fcb5481699169dbebb78a115",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4db1b4ffd45246a0ad678138d633df88"
          }
        },
        "a27d29f0a19b484ba0f6f495992dcefa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1f6c52631a884e1db366eb80c5c30026",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 207k/? [00:00&lt;00:00, 604kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_491e0a5f5a6f4863a24f099f59ec3517"
          }
        },
        "aaa0b25715664424868ec42a64d70781": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9bc6adc93c144357898953a96850e892": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "78a19f22fcb5481699169dbebb78a115": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4db1b4ffd45246a0ad678138d633df88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1f6c52631a884e1db366eb80c5c30026": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "491e0a5f5a6f4863a24f099f59ec3517": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "329f8f633de14ee0b69ed3544b564bcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_30d0fdb50e69427894c52fed2a5aba4e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_62d78a6cfe0849388520ac5fb321ba93",
              "IPY_MODEL_438b3bb62894430498e3b58dafafb529",
              "IPY_MODEL_f58d484e22a64b96a5ff8b3ab5034f04"
            ]
          }
        },
        "30d0fdb50e69427894c52fed2a5aba4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "62d78a6cfe0849388520ac5fb321ba93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7d708faa40bc4cae973bf270f5c37e34",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_70b50517a3ef42d9994225677af94d98"
          }
        },
        "438b3bb62894430498e3b58dafafb529": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_09ea1765b2854d9db3d5c5b3c4c8c6f6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_97f2b85bec724ac684f49a57eeedb28c"
          }
        },
        "f58d484e22a64b96a5ff8b3ab5034f04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_18c5d197ab66492e80adf1fd15b2b673",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 14742/0 [00:00&lt;00:00, 25975.66 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_241318756a36480599b5377da9f2c616"
          }
        },
        "7d708faa40bc4cae973bf270f5c37e34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "70b50517a3ef42d9994225677af94d98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "09ea1765b2854d9db3d5c5b3c4c8c6f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "97f2b85bec724ac684f49a57eeedb28c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "18c5d197ab66492e80adf1fd15b2b673": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "241318756a36480599b5377da9f2c616": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7c158a3c90b748ca88524739c10d8bfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7018405d174946bf88d2532b9ddb5c0a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_990109445da3436190ffdf8c9b1fc2ad",
              "IPY_MODEL_a72c8ec240ec4060bd936a29087d4139",
              "IPY_MODEL_6129960f89fe4d459322962e8a8de9b2"
            ]
          }
        },
        "7018405d174946bf88d2532b9ddb5c0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "990109445da3436190ffdf8c9b1fc2ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b652b7ecab9b463e95946bfcbe2455b6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b6b9b3cec0c14eaa8a8f3b89c8f192a7"
          }
        },
        "a72c8ec240ec4060bd936a29087d4139": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_db0342821771491cb0a9aa26b5b611f7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ee0dcd693d484b1bb47ffbfe439dcc7c"
          }
        },
        "6129960f89fe4d459322962e8a8de9b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8aaa111f35fd46b6afb80d8f16260f63",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 705/0 [00:00&lt;00:00, 7045.82 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_271546f7444c4773a80f5bced38021a1"
          }
        },
        "b652b7ecab9b463e95946bfcbe2455b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b6b9b3cec0c14eaa8a8f3b89c8f192a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "db0342821771491cb0a9aa26b5b611f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ee0dcd693d484b1bb47ffbfe439dcc7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8aaa111f35fd46b6afb80d8f16260f63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "271546f7444c4773a80f5bced38021a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d1d7b1a8cc4b439e92c8d35a980678c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f2e5781231844ccbb0d877477dc9cf1f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_923709de50004cdd8a1d8256693e9657",
              "IPY_MODEL_ae5693927605454fa0200eb08ea66ea9",
              "IPY_MODEL_75e4c0dc5c8d45ffb812631582b08e42"
            ]
          }
        },
        "f2e5781231844ccbb0d877477dc9cf1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "923709de50004cdd8a1d8256693e9657": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_27f554d2f9e14968b780b3568297b92d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2e26c94b0d144e9ebf33839338662220"
          }
        },
        "ae5693927605454fa0200eb08ea66ea9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_aea48b6a91e64c58911d3fbdf3d6b7e0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e2e4419b43834935a006a62cc0755f91"
          }
        },
        "75e4c0dc5c8d45ffb812631582b08e42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_53aac80dcb1e4c3fa55563cf142e5fe2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 734/0 [00:00&lt;00:00, 7335.69 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9d777c3e664f48a2b208904234dc28d3"
          }
        },
        "27f554d2f9e14968b780b3568297b92d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2e26c94b0d144e9ebf33839338662220": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aea48b6a91e64c58911d3fbdf3d6b7e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e2e4419b43834935a006a62cc0755f91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "53aac80dcb1e4c3fa55563cf142e5fe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9d777c3e664f48a2b208904234dc28d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2e7541a424ae4258b878d78a83c09295": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f3e2bb3ffbde464b94435a6e88b3cfc4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4202443ccecb4e4fa03c7c65018c4740",
              "IPY_MODEL_c54504273ca143e8befb24610ea07cbe",
              "IPY_MODEL_6ba2a510785f4dccac5a4f912cfb891d"
            ]
          }
        },
        "f3e2bb3ffbde464b94435a6e88b3cfc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4202443ccecb4e4fa03c7c65018c4740": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5e14afbe9b0f46b3a27cfe2e0ffdd903",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8f04498b32944740bd192f1be5154ba8"
          }
        },
        "c54504273ca143e8befb24610ea07cbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c3711f7bbaea49db8afd5a0530ac55bf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e447482e8b8f4ec2862fd51005343a37"
          }
        },
        "6ba2a510785f4dccac5a4f912cfb891d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e923351e7da742b993a35b3af7990f30",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3/3 [00:00&lt;00:00, 52.98it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e6ca70ed9994422eaa6ac936cc8cd4b0"
          }
        },
        "5e14afbe9b0f46b3a27cfe2e0ffdd903": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8f04498b32944740bd192f1be5154ba8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c3711f7bbaea49db8afd5a0530ac55bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e447482e8b8f4ec2862fd51005343a37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e923351e7da742b993a35b3af7990f30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e6ca70ed9994422eaa6ac936cc8cd4b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}