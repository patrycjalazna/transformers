{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/patrycjalazna/transformers/blob/main/projekt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsVorHKjEAuS"
      },
      "source": [
        "## ImportyðŸ’…ðŸ»ðŸ’…ðŸ»ðŸ’…ðŸ»"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4mxNeEwETVC",
        "outputId": "a2c4f53b-1a2a-4103-dfc3-ae5143743f86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.12.5\n",
            "  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.1 MB 4.4 MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.10.3\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.3 MB 29.5 MB/s \n",
            "\u001b[?25hCollecting sentencepiece==0.1.96\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.2 MB 46.2 MB/s \n",
            "\u001b[?25hCollecting datasets==1.16.1\n",
            "  Downloading datasets-1.16.1-py3-none-any.whl (298 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 298 kB 49.1 MB/s \n",
            "\u001b[?25hCollecting accelerate==0.5.1\n",
            "  Downloading accelerate-0.5.1-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58 kB 4.4 MB/s \n",
            "\u001b[?25hCollecting sacremoses==0.0.46\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895 kB 23.4 MB/s \n",
            "\u001b[?25hCollecting sacrebleu==2.0.0\n",
            "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90 kB 9.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.5) (3.4.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.5) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.5) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.5) (4.11.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.5) (1.21.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.5) (4.62.3)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 596 kB 41.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.12.5) (2019.12.20)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1 MB 42.5 MB/s \n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 243 kB 36.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets==1.16.1) (0.3.4)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets==1.16.1) (0.70.12.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets==1.16.1) (1.3.5)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.1.0-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 133 kB 36.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.16.1) (6.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.46) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.46) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.46) (7.1.2)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu==2.0.0) (0.8.9)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.12.5) (3.0.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.12.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.12.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.12.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.12.5) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==1.16.1) (2.0.11)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94 kB 3.5 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 271 kB 49.8 MB/s \n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 144 kB 52.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==1.16.1) (21.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.12.5) (3.7.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.16.1) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.16.1) (2.8.2)\n",
            "Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, pyyaml, fsspec, aiohttp, xxhash, tokenizers, sacremoses, portalocker, huggingface-hub, colorama, transformers, sentencepiece, sacrebleu, datasets, accelerate\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed accelerate-0.5.1 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 colorama-0.4.4 datasets-1.16.1 frozenlist-1.3.0 fsspec-2022.1.0 huggingface-hub-0.4.0 multidict-6.0.2 portalocker-2.4.0 pyyaml-6.0 sacrebleu-2.0.0 sacremoses-0.0.46 sentencepiece-0.1.96 tokenizers-0.10.3 transformers-4.12.5 xxhash-2.0.2 yarl-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install 'transformers==4.12.5' 'tokenizers==0.10.3' 'sentencepiece==0.1.96' 'datasets==1.16.1' 'accelerate==0.5.1' 'sacremoses==0.0.46' 'sacrebleu==2.0.0' 'torch';"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ttq7YMKmCGsd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import MSELoss, CrossEntropyLoss, BCEWithLogitsLoss\n",
        "from transformers import RobertaForSequenceClassification, RobertaModel\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "import json\n",
        "from pathlib import Path\n",
        "from typing import Dict, List\n",
        "from datasets import load_dataset\n",
        "import os\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGC7tQxkD_65"
      },
      "source": [
        "## ðŸ¤— Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6i8tCAdDE_X6"
      },
      "source": [
        "Dataset *emotion* jest zbiorem danych angielskich wiadomoÅ›ci na Twitterze zawierajÄ…cych szeÅ›Ä‡ podstawowych emocji: gniew, strach, radoÅ›Ä‡, miÅ‚oÅ›Ä‡, smutek i zaskoczenie."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQhq_Z1oF0cE"
      },
      "source": [
        "Link do datasetu: [hugginface](https://huggingface.co/datasets/emotion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YpVh9EvFkeM"
      },
      "source": [
        "PrzykÅ‚ad:\n",
        "\n",
        "```\n",
        "{\n",
        "    \"label\": 0,\n",
        "    \"text\": \"im feeling quite sad and sorry for myself but ill snap out of it soon\"\n",
        "}\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296,
          "referenced_widgets": [
            "e5b353287cba4e2b91ef611c44990330",
            "cdfdff424b174268a547336a85b5f43e",
            "6f022cfad7df4927ab4a8bfb82a0ea74",
            "0bd1a03796b241e6bc947bee56cbfd9b",
            "7d1cf194f8254611b72435af1bfa05d4",
            "76e9d4b880f74bdf85780c4dc6f6494c",
            "f8a3ef6dcf3044a4b86fa73f38a1dedc",
            "3e9b0f4310074f568af4aee5a4754aca",
            "ab660e703b824b37a60e2fe283411f0f",
            "3f241f591cdc419eb6cef53acad50912",
            "1d3ebfc2fd0c426182248cc4bba97303",
            "e591012c848248bfb64ef463f2e1f097",
            "dc04d6f4370d49408580c3c146e587bc",
            "b9ae3603130640dc8dfedac3385574f0",
            "e4c4e484ae40404c894dcaeb0c7ad242",
            "fd343007a5d8403187bccd877511c7fc",
            "7c8f9331f07949c0ba413497cf2eb2ef",
            "cb58a69e554d4a40a6e3cd6019d28a69",
            "970a405cd6f44606b4692fab7f23f9e4",
            "1108573852bc4ea4a3f96a1629f665bc",
            "cc5e139178f14661be798a051b2084c0",
            "0a42381aac5f4d5185605fc4237a6325",
            "3388d361cc5f418d869344763252e4f8",
            "6a522409c2c7470b8740a6cf810542f4",
            "937d6b8be0ac4c368f41fd99c9277386",
            "0a7d64d24ba94b9f8394aa33604f7a96",
            "90374892c74749a08a5cd07840ad432f",
            "402b397e45fe4778983903e11ca6ccf6",
            "288aa13994404db0b305c7a6a96ec508",
            "a5cc0cad6d914b0db9e073db58258038",
            "865e589a601d4cdbbcf13c452bfe04a1",
            "70104b66783947ae8f6294f62f8b34c9",
            "648b781bd2194755910cebf273f1cb5a",
            "57d086ab81824bf0af1f039ce839a738",
            "bb46a2b88f904787a0731923429d08e9",
            "88d739caeea34142a2f57aec393a9bb7",
            "79ad75e6fb7c44baa1697c8b84b47796",
            "00ebc78527c146e89a833640cee87cb0",
            "1a7e2282193e4b8a923beeb560f69675",
            "b96da57ccacf47e499ebe2a364ab10c0",
            "366a26758a97451685151081eb14809a",
            "cbc4c16889034d4cab98e992bcdd4864",
            "6ffe806afe4b464f9d9384f5dc284476",
            "79f9df32b6964c5d9eebdc45913984e1",
            "ee3be597f1154d318ed0173b9caff6ab",
            "5ff00ef858414a6d96440336a3d06b3a",
            "0e384d940c5a4fa592d2530c0d767107",
            "766173b8f9d741eba0af878b3b1f489b",
            "11be1e2f65b044079be97db90a2ec0f7",
            "187554fbce504ab89720a8b9274de559",
            "b7f0715ac3bf4bbe8956b15c015a2d63",
            "068c80f0ba584831a3f7b1442f111fa0",
            "57e3fec192f4401a9377812dab43b1ce",
            "4ec9359ffb424a81bd932e3670864abf",
            "e0e8ac3dc7a14a5bac6c7015ae7544f4",
            "283f704832254e038af2068f8e0bb5c5",
            "9ee7b459a60e41669bf9482760a0acc8",
            "13e484f101744bf88d22bb189d6bed83",
            "08bf77609b5a4cca89d0fb495bd9367c",
            "31a8e0bb8bb54505938b2f370d930cbd",
            "a458752b249845729cc1dae0a9e5d458",
            "0244fb841b4543939a9c413e60b9b8dc",
            "ad407122874442a6a9c07bcfd3fc6e2f",
            "0ec96581c3124816940c96ec41f0ec17",
            "05f2858ad9d349dbb4156c3777fbdd57",
            "11733b63339d407195c2c87699671611",
            "d211596c0dcd4b6597cbd72e33bc406e",
            "761ef443f508497f8002dd0d19876ba0",
            "342b37358cc6497cb08fa657c6a2132d",
            "8cab94a65390465ebb334e079b75246c",
            "ed76b8cea88e46248734664bf6ea5666",
            "2e0d56f5cded498d9e350ce288c8f43a",
            "3a5dea16cff44fe3b322c1afd2d078e7",
            "dc7100c6b706448386bc8e1036593979",
            "ae6c0393aa934c6f86a28bff6ca253df",
            "422bc3d46ccf49a5ba85a88acad3465f",
            "a4a39ff237784a1f941791cb9d2d3cfd",
            "40ab9a3eb5fc47679032946ed4ef1e89",
            "03ce62c360644c539371ecafdf0fd9dc",
            "ab367a398a5d45ba8c31946fb2a8c3e1",
            "8e4f28d5c9fb49848364eb19f4e30712",
            "40b746313f0c444e942049e39cb9ca40",
            "ff510201fbd14ed1a30e63be72b52a67",
            "c05deeb897e2489da33dc53234ddc9ff",
            "777aa998ba6b4a66ab7c40c974d16792",
            "4034d482358e44dc823888959e2f4cf6",
            "02160736a23c469bb7774ea17fd5edf8",
            "756476db0e114c9aba061914aae489fc",
            "7cd568581fd4421caf28226b36c09ef2",
            "5ed84338d0d24649810c36768f587952",
            "af366e73d49a468bb953b0112b5e872c",
            "326fcf344050406a976650fc5004faff",
            "55f99e4f573047c2b1d1dc49a369ed9c",
            "40316406b5854cd7af1baf4ab0dbf5ab",
            "3c5802d82d1b4a5d9331a08df5a6f4bb",
            "4f75ec098362434bb463a51a47c647ff",
            "95c8ecb35c194817a9f7d4a1a6faa944",
            "5f1c339e22da4d43a87367b840c833eb",
            "e80a2447320c417eb0f34794edeee389"
          ]
        },
        "id": "du4Zt20cEwKq",
        "outputId": "127e01b3-13d2-4e37-a3b8-c86e2827eb90"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5b353287cba4e2b91ef611c44990330",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.66k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e591012c848248bfb64ef463f2e1f097",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.61k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration default\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset emotion/default (download: 1.97 MiB, generated: 2.07 MiB, post-processed: Unknown size, total: 4.05 MiB) to /root/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3388d361cc5f418d869344763252e4f8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "57d086ab81824bf0af1f039ce839a738",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee3be597f1154d318ed0173b9caff6ab",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "283f704832254e038af2068f8e0bb5c5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d211596c0dcd4b6597cbd72e33bc406e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "40ab9a3eb5fc47679032946ed4ef1e89",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset emotion downloaded and prepared to /root/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7cd568581fd4421caf28226b36c09ef2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "dataset = load_dataset('emotion')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAlgEwdWGINg"
      },
      "source": [
        "Dane mamy automatycznie podzielone train set, validation set i test set w stosunku 8:1:1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1uh1PJPE-d5",
        "outputId": "8e142129-a800-4be7-b0ad-321756cb8d13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 16000\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 2000\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 2000\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "print(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dEWfFojGYu2"
      },
      "source": [
        "NastÄ™pnie tworzymy folder, w ktÃ³rym zapiszemy dane."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hi6YO6kPGU5C"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(\"./data\"):\n",
        "    os.makedirs(\"./data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EAaGp1LuGhK0"
      },
      "outputs": [],
      "source": [
        "train_path = Path('data/train.json')\n",
        "valid_path = Path('data/valid.json')\n",
        "test_path = Path('data/test.json')\n",
        "\n",
        "train_path_binary = Path('data/train_binary.json')\n",
        "valid_path_binary = Path('data/valid_binary.json')\n",
        "test_path_binary = Path('data/test_binary.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBgXI88RGmp-",
        "outputId": "f3244cad-ba40-4fd9-f5c2-9c35f504c25d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 16000\n",
            "Test: 2000\n",
            "Validation: 2000\n"
          ]
        }
      ],
      "source": [
        "data_train_list, data_valid_list, data_test_list = [], [], []\n",
        "\n",
        "for data_line, data_list in [\n",
        "  (dataset['train'], data_train_list),\n",
        "  (dataset['test'], data_test_list),\n",
        "  (dataset['validation'], data_valid_list)\n",
        "]:\n",
        "  for i, data in enumerate(data_line):\n",
        "    line = {\n",
        "      'label': int(data['label']),\n",
        "      'text': data['text'],\n",
        "    }\n",
        "    data_list.append(line)\n",
        "\n",
        "print(f'Train: {len(data_train_list)}')\n",
        "print(f'Test: {len(data_valid_list)}')\n",
        "print(f'Validation: {len(data_test_list)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "owwd-BQFBTqG"
      },
      "outputs": [],
      "source": [
        "# ZaleÅ¼y czy mapujemy tylko na pozytywne i negatywne czy na 6 co sÄ… w datasecie\n",
        "def get_map_label_translation(num_classes = 6):\n",
        "    '''\n",
        "    Possible numbers [2, 6]\n",
        "    '''\n",
        "    if(num_classes == 2):\n",
        "        return {\n",
        "            0: 'negative',\n",
        "            1: 'positive',\n",
        "            2: 'positive',\n",
        "            3: 'negative',\n",
        "            4: 'negative',\n",
        "            5: 'positive',\n",
        "        }\n",
        "    elif(num_classes == 6):\n",
        "        return {\n",
        "            0: 'sadness',\n",
        "            1: 'joy',\n",
        "            2: 'love',\n",
        "            3: 'anger',\n",
        "            4: 'fear',\n",
        "            5: 'suprise',\n",
        "        }\n",
        "\n",
        "def get_value_from_label(label):\n",
        "    if(label in [1, 2, 5]):\n",
        "        return 1\n",
        "    else: \n",
        "        return 0\n",
        "\n",
        "MAP_LABEL_TRANSLATION_2 = get_map_label_translation(2)\n",
        "MAP_LABEL_TRANSLATION_6 = get_map_label_translation(6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feE1t9t4G0pn",
        "outputId": "8dd16b1b-bdad-44db-9739-dea65eef09ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Stats for train set on 6 labels --\n",
            "Label sadness:   4666\n",
            "Label joy:   5362\n",
            "Label love:   1304\n",
            "Label anger:   2159\n",
            "Label fear:   1937\n",
            "Label suprise:    572\n",
            "-- Stats for test set on 6 labels --\n",
            "Label sadness:    581\n",
            "Label joy:    695\n",
            "Label love:    159\n",
            "Label anger:    275\n",
            "Label fear:    224\n",
            "Label suprise:     66\n",
            "-- Stats for validation set on 6 labels--\n",
            "Label sadness:    550\n",
            "Label joy:    704\n",
            "Label love:    178\n",
            "Label anger:    275\n",
            "Label fear:    212\n",
            "Label suprise:     81\n",
            "-- Stats for train set on 2 labels --\n",
            "Label negative:   8762\n",
            "Label positive:   7238\n",
            "-- Stats for test set on 2 labels --\n",
            "Label negative:   1080\n",
            "Label positive:    920\n",
            "-- Stats for validation set on 2 labels--\n",
            "Label negative:   1037\n",
            "Label positive:    963\n"
          ]
        }
      ],
      "source": [
        "data_class_test = {}\n",
        "data_class_train = {}\n",
        "data_class_validation = {}\n",
        "\n",
        "data_class_test_binary = {}\n",
        "data_class_train_binary = {}\n",
        "data_class_validation_binary = {}\n",
        "\n",
        "for label in MAP_LABEL_TRANSLATION_6:\n",
        "  if(MAP_LABEL_TRANSLATION_6[label] not in data_class_test):\n",
        "    data_class_test[MAP_LABEL_TRANSLATION_6[label]] = []\n",
        "    data_class_validation[MAP_LABEL_TRANSLATION_6[label]] = []\n",
        "    data_class_train[MAP_LABEL_TRANSLATION_6[label]] = []\n",
        "\n",
        "for label in MAP_LABEL_TRANSLATION_2:\n",
        "  if(MAP_LABEL_TRANSLATION_2[label] not in data_class_test):\n",
        "    data_class_test_binary[MAP_LABEL_TRANSLATION_2[label]] = []\n",
        "    data_class_validation_binary[MAP_LABEL_TRANSLATION_2[label]] = []\n",
        "    data_class_train_binary[MAP_LABEL_TRANSLATION_2[label]] = []\n",
        "\n",
        "for data in data_valid_list:\n",
        "  data_class_validation[MAP_LABEL_TRANSLATION_6[int(data['label'])]].append(data)\n",
        "for data in data_train_list:\n",
        "  data_class_train[MAP_LABEL_TRANSLATION_6[int(data['label'])]].append(data)\n",
        "for data in data_test_list:\n",
        "  data_class_test[MAP_LABEL_TRANSLATION_6[int(data['label'])]].append(data)\n",
        "\n",
        "for data in data_valid_list:\n",
        "  data_class_validation_binary[MAP_LABEL_TRANSLATION_2[int(data['label'])]].append(data)\n",
        "for data in data_train_list:\n",
        "  data_class_train_binary[MAP_LABEL_TRANSLATION_2[int(data['label'])]].append(data)\n",
        "for data in data_test_list:\n",
        "  data_class_test_binary[MAP_LABEL_TRANSLATION_2[int(data['label'])]].append(data)\n",
        "\n",
        "print('-- Stats for train set on 6 labels --')\n",
        "for label in data_class_train:\n",
        "  print(f'Label {label}: {len(data_class_train[label]):6d}')\n",
        "print('-- Stats for test set on 6 labels --')\n",
        "for label in data_class_test:\n",
        "  print(f'Label {label}: {len(data_class_test[label]):6d}')\n",
        "print('-- Stats for validation set on 6 labels--')\n",
        "for label in data_class_validation:\n",
        "  print(f'Label {label}: {len(data_class_validation[label]):6d}')\n",
        "  \n",
        "print('-- Stats for train set on 2 labels --')\n",
        "for label in data_class_train_binary:\n",
        "  print(f'Label {label}: {len(data_class_train_binary[label]):6d}')\n",
        "print('-- Stats for test set on 2 labels --')\n",
        "for label in data_class_test_binary:\n",
        "  print(f'Label {label}: {len(data_class_test_binary[label]):6d}')\n",
        "print('-- Stats for validation set on 2 labels--')\n",
        "for label in data_class_validation_binary:\n",
        "  print(f'Label {label}: {len(data_class_validation_binary[label]):6d}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5N7PYFuKHz-2"
      },
      "outputs": [],
      "source": [
        "   \n",
        "def remove_if_exists(f):\n",
        "    if(Path(f).exists()):\n",
        "        f.unlink()\n",
        "\n",
        "def save_unchanged(f, data, binary = True):\n",
        "    remove_if_exists(f)\n",
        "    print(f'Saving into: {f}')\n",
        "    with open(f, 'wt') as f_write:\n",
        "        for data_line in data:\n",
        "            if(binary):\n",
        "                data_line['label'] = get_value_from_label((data_line['label']))\n",
        "            data_line_str = json.dumps(data_line)\n",
        "            f_write.write(f'{data_line_str}\\n')\n",
        "\n",
        "def save_as_translations(f, data_classes, num_entries):\n",
        "    file_name = 'translations-' + f.name\n",
        "    file_path = f.parent / file_name\n",
        "    stats = {}\n",
        "    remove_if_exists(Path(file_path))\n",
        "    print(f'Saving into: {file_path}')\n",
        "    \n",
        "    with open(file_path, 'wt') as f_write:\n",
        "        for class_list in data_classes:\n",
        "            if(num_entries > len(data_classes[class_list])):\n",
        "                samples = data_classes[class_list]\n",
        "            else:\n",
        "                samples = random.sample(data_classes[class_list], num_entries)\n",
        "\n",
        "            stats[f'{class_list} entries'] = len(samples)\n",
        "\n",
        "            for data_line in samples:\n",
        "                data_line['label'] = class_list\n",
        "                data_line_str = json.dumps(data_line)\n",
        "                f_write.write(f'{data_line_str}\\n')\n",
        "        print(stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1LayjuGH1ye",
        "outputId": "1b040743-36ab-44f6-dbbc-0a3cb75fd308"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving into: data/train.json\n",
            "Saving into: data/translations-train.json\n",
            "{'sadness entries': 1000, 'joy entries': 1000, 'love entries': 1000, 'anger entries': 1000, 'fear entries': 1000, 'suprise entries': 572}\n",
            "Saving into: data/valid.json\n",
            "Saving into: data/translations-valid.json\n",
            "{'sadness entries': 100, 'joy entries': 100, 'love entries': 100, 'anger entries': 100, 'fear entries': 100, 'suprise entries': 81}\n",
            "Saving into: data/test.json\n",
            "Saving into: data/translations-test.json\n",
            "{'sadness entries': 100, 'joy entries': 100, 'love entries': 100, 'anger entries': 100, 'fear entries': 100, 'suprise entries': 66}\n",
            "Saving into: data/train_binary.json\n",
            "Saving into: data/translations-train_binary.json\n",
            "{'negative entries': 1000, 'positive entries': 1000}\n",
            "Saving into: data/valid_binary.json\n",
            "Saving into: data/translations-valid_binary.json\n",
            "{'negative entries': 100, 'positive entries': 100}\n",
            "Saving into: data/test_binary.json\n",
            "Saving into: data/translations-test_binary.json\n",
            "{'negative entries': 100, 'positive entries': 100}\n"
          ]
        }
      ],
      "source": [
        "# Rozmiar zbiorÃ³w, podana wartoÅ›Ä‡ to iloÅ›Ä‡ lini dla kaÅ¼degj klasy, jeÅ¼eli dana klasa nie posiada danej iloÅ›ci lini, wszystkie linie zostaja przekazane.\n",
        "def get_num_of_samples(set_name):\n",
        "    if(set_name == 'train'):\n",
        "        return 1000\n",
        "    else:\n",
        "        return 100\n",
        "\n",
        "for file_path, data_to_save, data_classes, num_entries in [ (train_path, data_train_list, data_class_train, get_num_of_samples('train') ), (valid_path, data_valid_list, data_class_validation, get_num_of_samples('valid')), (test_path, data_test_list, data_class_test, get_num_of_samples('test'))]:\n",
        "  save_unchanged(file_path, data_to_save, False)\n",
        "  save_as_translations(file_path, data_classes, num_entries)\n",
        "\n",
        "for file_path, data_to_save, data_classes, num_entries in [ (train_path_binary, data_train_list, data_class_train_binary, get_num_of_samples('train') ), (valid_path_binary, data_valid_list, data_class_validation_binary, get_num_of_samples('valid')), (test_path_binary, data_test_list, data_class_test_binary, get_num_of_samples('test'))]:\n",
        "  save_unchanged(file_path, data_to_save)\n",
        "  save_as_translations(file_path, data_classes, num_entries)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ScsRm2eBTqN"
      },
      "source": [
        "## ðŸ¤— Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16NAZ70PBTqO"
      },
      "source": [
        "Pobranie skryptu dostÄ™pnego w bibliotece transformes potrzebnego do uruchomienia modelu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "j-FiY0kIBTqO",
        "outputId": "5d907c62-4b40-41ff-aef2-a77135ae1cc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-21 16:03:54--  https://raw.githubusercontent.com/huggingface/transformers/v4.12.5/examples/pytorch/text-classification/run_glue_no_trainer.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21091 (21K) [text/plain]\n",
            "Saving to: â€˜original_run_glue_no_trainer.pyâ€™\n",
            "\n",
            "original_run_glue_n 100%[===================>]  20.60K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2022-02-21 16:03:54 (16.2 MB/s) - â€˜original_run_glue_no_trainer.pyâ€™ saved [21091/21091]\n",
            "\n",
            "--2022-02-21 16:03:54--  https://raw.githubusercontent.com/patrycjalazna/transformers/main/gpt2.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9202 (9.0K) [text/plain]\n",
            "Saving to: â€˜gpt2.pyâ€™\n",
            "\n",
            "gpt2.py             100%[===================>]   8.99K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-02-21 16:03:55 (61.5 MB/s) - â€˜gpt2.pyâ€™ saved [9202/9202]\n",
            "\n",
            "--2022-02-21 16:03:55--  https://raw.githubusercontent.com/patrycjalazna/transformers/main/roberta.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10993 (11K) [text/plain]\n",
            "Saving to: â€˜roberta.pyâ€™\n",
            "\n",
            "roberta.py          100%[===================>]  10.74K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2022-02-21 16:03:55 (20.8 MB/s) - â€˜roberta.pyâ€™ saved [10993/10993]\n",
            "\n",
            "--2022-02-21 16:03:55--  https://raw.githubusercontent.com/patrycjalazna/transformers/main/run_glue_no_trainer.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 25884 (25K) [text/plain]\n",
            "Saving to: â€˜run_glue_no_trainer.pyâ€™\n",
            "\n",
            "run_glue_no_trainer 100%[===================>]  25.28K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2022-02-21 16:03:56 (10.9 MB/s) - â€˜run_glue_no_trainer.pyâ€™ saved [25884/25884]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget 'https://raw.githubusercontent.com/huggingface/transformers/v4.12.5/examples/pytorch/text-classification/run_glue_no_trainer.py' -O 'original_run_glue_no_trainer.py'\n",
        "!wget 'https://raw.githubusercontent.com/patrycjalazna/transformers/main/gpt2.py' -O 'gpt2.py'\n",
        "!wget 'https://raw.githubusercontent.com/patrycjalazna/transformers/main/roberta.py' -O 'roberta.py'\n",
        "!wget 'https://raw.githubusercontent.com/patrycjalazna/transformers/main/run_glue_no_trainer.py' -O 'run_glue_no_trainer.py'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNfOz8lCBTqP"
      },
      "source": [
        "## GPT2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5G1UM9RBTqQ"
      },
      "source": [
        "Podstawowy model GPT2, prÃ³ba polegaÅ‚a na zwiÄ™kszeniu iloÅ›ci epoch co poskutkowaÅ‚o wzrostem accuracy z 0.83 na 0.938\n",
        "- Epoch 0: accuracy: 0.9095\n",
        "- Epoch 1: accuracy: 0.9315\n",
        "- Epoch 2: accuracy: 0.9385\n",
        "- Epoch 3: accuracy: 0.938\n",
        "- Evaluation: accuracy: 0.9275"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WZ3aiFGuBTqQ",
        "outputId": "a2fcc04b-4f45-44d6-da20-3087d19442ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "02/21/2022 16:04:01 - INFO - __main__ - Distributed environment: NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "Use FP16 precision: False\n",
            "\n",
            "02/21/2022 16:04:01 - WARNING - datasets.builder - Using custom data configuration default-a7eb5dd65320bcb5\n",
            "Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-a7eb5dd65320bcb5/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426...\n",
            "100% 3/3 [00:00<00:00, 9265.77it/s]\n",
            "100% 3/3 [00:00<00:00, 1259.80it/s]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-a7eb5dd65320bcb5/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426. Subsequent calls will reuse this data.\n",
            "100% 3/3 [00:00<00:00, 951.95it/s]\n",
            "https://huggingface.co/gpt2/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpnvrikdgn\n",
            "Downloading: 100% 665/665 [00:00<00:00, 505kB/s]\n",
            "storing https://huggingface.co/gpt2/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
            "creating metadata file for /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
            "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
            "Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\",\n",
            "    \"5\": \"LABEL_5\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4,\n",
            "    \"LABEL_5\": 5\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
            "Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "https://huggingface.co/gpt2/resolve/main/vocab.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpxfcka0lm\n",
            "Downloading: 100% 0.99M/0.99M [00:01<00:00, 959kB/s]\n",
            "storing https://huggingface.co/gpt2/resolve/main/vocab.json in cache at /root/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
            "creating metadata file for /root/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
            "https://huggingface.co/gpt2/resolve/main/merges.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp2m35aswr\n",
            "Downloading: 100% 446k/446k [00:00<00:00, 505kB/s]\n",
            "storing https://huggingface.co/gpt2/resolve/main/merges.txt in cache at /root/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "creating metadata file for /root/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "https://huggingface.co/gpt2/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpdi6mg5s8\n",
            "Downloading: 100% 1.29M/1.29M [00:01<00:00, 1.24MB/s]\n",
            "storing https://huggingface.co/gpt2/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/16a2f78023c8dc511294f0c97b5e10fde3ef9889ad6d11ffaa2a00714e73926e.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
            "creating metadata file for /root/.cache/huggingface/transformers/16a2f78023c8dc511294f0c97b5e10fde3ef9889ad6d11ffaa2a00714e73926e.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
            "loading file https://huggingface.co/gpt2/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
            "loading file https://huggingface.co/gpt2/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "loading file https://huggingface.co/gpt2/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/16a2f78023c8dc511294f0c97b5e10fde3ef9889ad6d11ffaa2a00714e73926e.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
            "loading file https://huggingface.co/gpt2/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/gpt2/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/gpt2/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
            "Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "02/21/2022 16:04:16 - INFO - __main__ - Return hidden states from model: False\n",
            "02/21/2022 16:04:16 - INFO - __main__ - Using implementation from: AutoModelForSequenceClassification\n",
            "https://huggingface.co/gpt2/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmps8kk6jy8\n",
            "Downloading: 100% 523M/523M [00:12<00:00, 44.8MB/s]\n",
            "storing https://huggingface.co/gpt2/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/752929ace039baa8ef70fe21cdf9ab9445773d20e733cf693d667982e210837e.323c769945a351daa25546176f8208b3004b6f563438a7603e7932bae9025925\n",
            "creating metadata file for /root/.cache/huggingface/transformers/752929ace039baa8ef70fe21cdf9ab9445773d20e733cf693d667982e210837e.323c769945a351daa25546176f8208b3004b6f563438a7603e7932bae9025925\n",
            "loading weights file https://huggingface.co/gpt2/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/752929ace039baa8ef70fe21cdf9ab9445773d20e733cf693d667982e210837e.323c769945a351daa25546176f8208b3004b6f563438a7603e7932bae9025925\n",
            "All model checkpoint weights were used when initializing GPT2ForSequenceClassification.\n",
            "\n",
            "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using pad_token, but it is not set yet.\n",
            "02/21/2022 16:04:31 - INFO - __main__ - Set PAD token to EOS: <|endoftext|>\n",
            "Running tokenizer on dataset: 100% 16/16 [00:01<00:00, 15.91ba/s]\n",
            "Running tokenizer on dataset: 100% 2/2 [00:00<00:00, 18.35ba/s]\n",
            "Running tokenizer on dataset: 100% 2/2 [00:00<00:00, 18.35ba/s]\n",
            "02/21/2022 16:04:32 - INFO - __main__ - Sample 13385 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [72, 1254, 881, 517, 6563, 326, 597, 584, 640, 220, 425, 587, 284, 773, 544, 287, 262, 1613], 'labels': 1}.\n",
            "02/21/2022 16:04:32 - INFO - __main__ - Sample 1006 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [72, 991, 1254, 588, 262, 13938, 326, 1312, 836, 256, 588, 428, 2968, 905, 7584, 502, 287, 257, 6536, 351, 661, 508, 4829, 37793, 393, 661, 508, 393, 508, 8711, 262, 4227, 774, 8242, 572, 262, 12983, 286, 19317, 641, 666, 50213], 'labels': 1}.\n",
            "02/21/2022 16:04:32 - INFO - __main__ - Sample 3288 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1], 'input_ids': [72, 1254, 588, 10818, 1654, 286, 340], 'labels': 1}.\n",
            "Downloading: 3.20kB [00:00, 3.45MB/s]       \n",
            "02/21/2022 16:04:44 - INFO - __main__ - ***** Running training *****\n",
            "02/21/2022 16:04:44 - INFO - __main__ -   Num examples = 16000\n",
            "02/21/2022 16:04:44 - INFO - __main__ -   Num Epochs = 4\n",
            "02/21/2022 16:04:44 - INFO - __main__ -   Instantaneous batch size per device = 24\n",
            "02/21/2022 16:04:44 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 24\n",
            "02/21/2022 16:04:44 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "02/21/2022 16:04:44 - INFO - __main__ -   Total optimization steps = 2668\n",
            " 25% 667/2668 [05:13<15:07,  2.21it/s]02/21/2022 16:10:10 - INFO - __main__ - Epoch 0: {'accuracy': 0.872}\n",
            " 50% 1334/2668 [10:39<09:37,  2.31it/s]02/21/2022 16:15:36 - INFO - __main__ - Epoch 1: {'accuracy': 0.923}\n",
            " 75% 2001/2668 [16:05<04:40,  2.38it/s]02/21/2022 16:21:02 - INFO - __main__ - Epoch 2: {'accuracy': 0.934}\n",
            "100% 2668/2668 [21:32<00:00,  2.21it/s]02/21/2022 16:26:29 - INFO - __main__ - Epoch 3: {'accuracy': 0.931}\n",
            "02/21/2022 16:26:41 - INFO - __main__ - Test-set evaluation: {'accuracy': 0.924}\n",
            "Configuration saved in out/gpt2/version1/config.json\n",
            "Model weights saved in out/gpt2/version1/pytorch_model.bin\n",
            "tokenizer config file saved in out/gpt2/version1/tokenizer_config.json\n",
            "Special tokens file saved in out/gpt2/version1/special_tokens_map.json\n",
            "100% 2668/2668 [21:58<00:00,  2.02it/s]\n"
          ]
        }
      ],
      "source": [
        "!python run_glue_no_trainer.py \\\n",
        "  --model_name_or_path gpt2 \\\n",
        "  --train_file data/train.json  \\\n",
        "  --validation_file data/valid.json \\\n",
        "  --test_file data/test.json \\\n",
        "  --per_device_train_batch_size 24 \\\n",
        "  --per_device_eval_batch_size 24 \\\n",
        "  --max_length 128 \\\n",
        "  --learning_rate 2e-5 \\\n",
        "  --num_train_epochs 4 \\\n",
        "  --output_dir out/gpt2/version1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vo5BtfxwBTqR"
      },
      "source": [
        "### Version 2\n",
        "#### GPT2ForSequenceClassificationCustom\n",
        "Model z pliku gpt2.py, dodatkowo uruchomiony z flagÄ… freeze_model uruchomiony na 4 epochach:\n",
        "- Epoch 0 accuracy: 0.462\n",
        "- Epoch 1 accuracy: 0.4645\n",
        "- Epoch 2 accuracy: 0.4615\n",
        "- Epoch 3 accuracy: 0.4745\n",
        "- Evaluation accurracy: 0.4795"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "xyWaY-6KBTqS",
        "outputId": "973b02bf-648e-46b3-95d3-b87425748e70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "02/21/2022 16:26:49 - INFO - __main__ - Distributed environment: NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "Use FP16 precision: False\n",
            "\n",
            "02/21/2022 16:26:49 - WARNING - datasets.builder - Using custom data configuration default-a7eb5dd65320bcb5\n",
            "02/21/2022 16:26:49 - WARNING - datasets.builder - Reusing dataset json (/root/.cache/huggingface/datasets/json/default-a7eb5dd65320bcb5/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426)\n",
            "100% 3/3 [00:00<00:00, 784.13it/s]\n",
            "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
            "Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\",\n",
            "    \"5\": \"LABEL_5\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4,\n",
            "    \"LABEL_5\": 5\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
            "Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/gpt2/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
            "loading file https://huggingface.co/gpt2/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "loading file https://huggingface.co/gpt2/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/16a2f78023c8dc511294f0c97b5e10fde3ef9889ad6d11ffaa2a00714e73926e.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
            "loading file https://huggingface.co/gpt2/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/gpt2/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/gpt2/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
            "Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "02/21/2022 16:26:58 - INFO - __main__ - Return hidden states from model: False\n",
            "02/21/2022 16:26:58 - INFO - __main__ - Using implementation from: GPT2ForSequenceClassificationCustom\n",
            "loading weights file https://huggingface.co/gpt2/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/752929ace039baa8ef70fe21cdf9ab9445773d20e733cf693d667982e210837e.323c769945a351daa25546176f8208b3004b6f563438a7603e7932bae9025925\n",
            "All model checkpoint weights were used when initializing GPT2ForSequenceClassificationCustom.\n",
            "\n",
            "Some weights of GPT2ForSequenceClassificationCustom were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.dense_2.weight', 'score.out_proj.weight', 'score.dense_2.bias', 'score.dense_1_input.weight', 'score.dense_1_hidden.bias', 'score.dense_3.weight', 'score.dense_3.bias', 'score.dense_1_hidden.weight', 'score.dense_1_input.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "02/21/2022 16:27:02 - INFO - __main__ - Freezing model weights\n",
            "Using pad_token, but it is not set yet.\n",
            "02/21/2022 16:27:02 - INFO - __main__ - Set PAD token to EOS: <|endoftext|>\n",
            "Running tokenizer on dataset: 100% 16/16 [00:01<00:00, 14.69ba/s]\n",
            "Running tokenizer on dataset: 100% 2/2 [00:00<00:00, 19.08ba/s]\n",
            "Running tokenizer on dataset: 100% 2/2 [00:00<00:00, 19.75ba/s]\n",
            "02/21/2022 16:27:03 - INFO - __main__ - Sample 4652 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [72, 1254, 534, 5848, 287, 6164, 4585, 329, 674, 14142], 'labels': 1}.\n",
            "02/21/2022 16:27:03 - INFO - __main__ - Sample 14741 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [72, 1682, 1254, 24776, 286, 661, 994, 826, 783], 'labels': 4}.\n",
            "02/21/2022 16:27:03 - INFO - __main__ - Sample 12530 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [72, 7765, 510, 1312, 6537, 326, 616, 15857, 88, 318, 9583, 290, 1312, 1254, 845, 42014], 'labels': 2}.\n",
            "02/21/2022 16:27:07 - INFO - __main__ - ***** Running training *****\n",
            "02/21/2022 16:27:07 - INFO - __main__ -   Num examples = 16000\n",
            "02/21/2022 16:27:07 - INFO - __main__ -   Num Epochs = 4\n",
            "02/21/2022 16:27:07 - INFO - __main__ -   Instantaneous batch size per device = 24\n",
            "02/21/2022 16:27:07 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 24\n",
            "02/21/2022 16:27:07 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "02/21/2022 16:27:07 - INFO - __main__ -   Total optimization steps = 2668\n",
            " 25% 667/2668 [02:11<05:48,  5.74it/s]02/21/2022 16:29:33 - INFO - __main__ - Epoch 0: {'accuracy': 0.427}\n",
            " 50% 1334/2668 [04:37<03:36,  6.17it/s]02/21/2022 16:31:59 - INFO - __main__ - Epoch 1: {'accuracy': 0.449}\n",
            " 75% 2001/2668 [07:03<02:04,  5.34it/s]02/21/2022 16:34:25 - INFO - __main__ - Epoch 2: {'accuracy': 0.4625}\n",
            "100% 2668/2668 [09:30<00:00,  5.46it/s]02/21/2022 16:36:51 - INFO - __main__ - Epoch 3: {'accuracy': 0.464}\n",
            "02/21/2022 16:37:05 - INFO - __main__ - Test-set evaluation: {'accuracy': 0.4735}\n",
            "Configuration saved in out/gpt2/version2/config.json\n",
            "Model weights saved in out/gpt2/version2/pytorch_model.bin\n",
            "tokenizer config file saved in out/gpt2/version2/tokenizer_config.json\n",
            "Special tokens file saved in out/gpt2/version2/special_tokens_map.json\n",
            "100% 2668/2668 [09:59<00:00,  4.45it/s]\n"
          ]
        }
      ],
      "source": [
        "!python run_glue_no_trainer.py \\\n",
        "  --model_name_or_path gpt2 \\\n",
        "  --train_file data/train.json  \\\n",
        "  --validation_file data/valid.json \\\n",
        "  --test_file data/test.json \\\n",
        "  --per_device_train_batch_size 24 \\\n",
        "  --per_device_eval_batch_size 24 \\\n",
        "  --max_length 128 \\\n",
        "  --freeze_model \\\n",
        "  --custom_model \\\n",
        "  --learning_rate 2e-5 \\\n",
        "  --num_train_epochs 4 \\\n",
        "  --output_dir out/gpt2/version2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiPyvVoXBTqS"
      },
      "source": [
        "### Version 3\n",
        "#### GPT2ForSequenceClassificationCustomVersion2\n",
        "Dodana zostaÅ‚a nowa warstwa, dodatkowo uruchomiony z flagÄ… freeze_model na 2 epochach. Zmieniony zostaÅ‚ parametr max_length z 128 na 256, oraz train_batch_size z 24 na 32: \n",
        "- Epoch 0: accuracy: 0.3765\n",
        "- Epoch 1: accuracy: 0.4210\n",
        "- Evaluation accurracy: 0.4339"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "y9M0h98aIPdd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "SruNAhAjBTqT",
        "outputId": "60b50c87-facb-40d1-edd7-05b91d60ce40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "02/21/2022 16:37:12 - INFO - __main__ - Distributed environment: NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "Use FP16 precision: False\n",
            "\n",
            "02/21/2022 16:37:13 - WARNING - datasets.builder - Using custom data configuration default-a7eb5dd65320bcb5\n",
            "02/21/2022 16:37:13 - WARNING - datasets.builder - Reusing dataset json (/root/.cache/huggingface/datasets/json/default-a7eb5dd65320bcb5/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426)\n",
            "100% 3/3 [00:00<00:00, 803.15it/s]\n",
            "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
            "Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\",\n",
            "    \"5\": \"LABEL_5\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4,\n",
            "    \"LABEL_5\": 5\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
            "Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/gpt2/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
            "loading file https://huggingface.co/gpt2/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "loading file https://huggingface.co/gpt2/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/16a2f78023c8dc511294f0c97b5e10fde3ef9889ad6d11ffaa2a00714e73926e.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
            "loading file https://huggingface.co/gpt2/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/gpt2/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/gpt2/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
            "Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "02/21/2022 16:37:21 - INFO - __main__ - Return hidden states from model: True\n",
            "02/21/2022 16:37:21 - INFO - __main__ - Using implementation from: GPT2ForSequenceClassificationCustom\n",
            "loading weights file https://huggingface.co/gpt2/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/752929ace039baa8ef70fe21cdf9ab9445773d20e733cf693d667982e210837e.323c769945a351daa25546176f8208b3004b6f563438a7603e7932bae9025925\n",
            "All model checkpoint weights were used when initializing GPT2ForSequenceClassificationCustom.\n",
            "\n",
            "Some weights of GPT2ForSequenceClassificationCustom were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.dense_1_input.bias', 'score.dense_2.weight', 'score.dense_1_input.weight', 'score.dense_2.bias', 'score.out_proj.weight', 'score.dense_3.bias', 'score.dense_1_hidden.weight', 'score.dense_3.weight', 'score.dense_1_hidden.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "02/21/2022 16:37:25 - INFO - __main__ - Freezing model weights\n",
            "Using pad_token, but it is not set yet.\n",
            "02/21/2022 16:37:25 - INFO - __main__ - Set PAD token to EOS: <|endoftext|>\n",
            "Running tokenizer on dataset: 100% 16/16 [00:01<00:00, 14.93ba/s]\n",
            "Running tokenizer on dataset: 100% 2/2 [00:00<00:00, 19.51ba/s]\n",
            "Running tokenizer on dataset: 100% 2/2 [00:00<00:00, 19.24ba/s]\n",
            "02/21/2022 16:37:27 - INFO - __main__ - Sample 11723 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [72, 1254, 355, 996, 262, 1613, 734, 1933, 423, 587, 257, 6283, 23137, 1711, 2402, 262, 772, 16195, 4320, 286, 2279, 616, 812, 287, 266, 8816, 547, 290, 547, 407], 'labels': 4}.\n",
            "02/21/2022 16:37:27 - INFO - __main__ - Sample 4732 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [72, 460, 1254, 340, 2406, 290, 545, 5295, 284, 766, 340, 832], 'labels': 1}.\n",
            "02/21/2022 16:37:27 - INFO - __main__ - Sample 14975 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [72, 750, 1254, 326, 262, 7464, 373, 6547, 13999, 290, 42547, 2148, 262, 16512, 1312, 373, 2045, 329, 475, 7692, 428, 373, 6754, 10165, 379, 663, 18822], 'labels': 3}.\n",
            "02/21/2022 16:37:31 - INFO - __main__ - ***** Running training *****\n",
            "02/21/2022 16:37:31 - INFO - __main__ -   Num examples = 16000\n",
            "02/21/2022 16:37:31 - INFO - __main__ -   Num Epochs = 2\n",
            "02/21/2022 16:37:31 - INFO - __main__ -   Instantaneous batch size per device = 32\n",
            "02/21/2022 16:37:31 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "02/21/2022 16:37:31 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "02/21/2022 16:37:31 - INFO - __main__ -   Total optimization steps = 1000\n",
            " 50% 500/1000 [02:13<02:20,  3.56it/s]02/21/2022 16:39:58 - INFO - __main__ - Epoch 0: {'accuracy': 0.377}\n",
            "100% 1000/1000 [04:40<00:00,  3.83it/s]02/21/2022 16:42:25 - INFO - __main__ - Epoch 1: {'accuracy': 0.451}\n",
            "02/21/2022 16:42:38 - INFO - __main__ - Test-set evaluation: {'accuracy': 0.4655}\n",
            "Configuration saved in out/gpt2/version3/config.json\n",
            "Model weights saved in out/gpt2/version3/pytorch_model.bin\n",
            "tokenizer config file saved in out/gpt2/version3/tokenizer_config.json\n",
            "Special tokens file saved in out/gpt2/version3/special_tokens_map.json\n",
            "100% 1000/1000 [05:09<00:00,  3.23it/s]\n"
          ]
        }
      ],
      "source": [
        "!python run_glue_no_trainer.py \\\n",
        "  --model_name_or_path gpt2 \\\n",
        "  --train_file data/train.json  \\\n",
        "  --validation_file data/valid.json \\\n",
        "  --test_file data/test.json \\\n",
        "  --per_device_train_batch_size 32 \\\n",
        "  --per_device_eval_batch_size 32 \\\n",
        "  --max_length 254 \\\n",
        "  --freeze_model \\\n",
        "  --custom_model \\\n",
        "  --return_hidden_states \\\n",
        "  --learning_rate 2e-5 \\\n",
        "  --num_train_epochs 2 \\\n",
        "  --output_dir out/gpt2/version3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kt7z4QlVBTqT"
      },
      "source": [
        "### Version 4\n",
        "#### GPT2ForSequenceClassificationCustomVersion2\n",
        "Dodana zostaÅ‚a nowa warstwa, dodatkowo uruchomiony z flagÄ… freeze_model na 8 epochach. Zmieniony zostaÅ‚ parametr, oraz train_batch_size z 24 na 16: \n",
        "- Epoch 0: accuracy: 0.3765\n",
        "- Epoch 1: accuracy: 0.4210\n",
        "- Evaluation accurracy: 0.4339"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "xg7oaa1nBTqU",
        "outputId": "6ccfa084-4abf-45dd-9fd0-99989dcf0063",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "02/21/2022 16:42:46 - INFO - __main__ - Distributed environment: NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "Use FP16 precision: False\n",
            "\n",
            "02/21/2022 16:42:46 - WARNING - datasets.builder - Using custom data configuration default-a7eb5dd65320bcb5\n",
            "02/21/2022 16:42:46 - WARNING - datasets.builder - Reusing dataset json (/root/.cache/huggingface/datasets/json/default-a7eb5dd65320bcb5/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426)\n",
            "100% 3/3 [00:00<00:00, 814.59it/s]\n",
            "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
            "Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\",\n",
            "    \"5\": \"LABEL_5\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4,\n",
            "    \"LABEL_5\": 5\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
            "Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/gpt2/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
            "loading file https://huggingface.co/gpt2/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "loading file https://huggingface.co/gpt2/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/16a2f78023c8dc511294f0c97b5e10fde3ef9889ad6d11ffaa2a00714e73926e.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
            "loading file https://huggingface.co/gpt2/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/gpt2/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/gpt2/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
            "Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "02/21/2022 16:42:55 - INFO - __main__ - Return hidden states from model: True\n",
            "02/21/2022 16:42:55 - INFO - __main__ - Using implementation from: GPT2ForSequenceClassificationCustom\n",
            "loading weights file https://huggingface.co/gpt2/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/752929ace039baa8ef70fe21cdf9ab9445773d20e733cf693d667982e210837e.323c769945a351daa25546176f8208b3004b6f563438a7603e7932bae9025925\n",
            "All model checkpoint weights were used when initializing GPT2ForSequenceClassificationCustom.\n",
            "\n",
            "Some weights of GPT2ForSequenceClassificationCustom were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.dense_1_hidden.bias', 'score.dense_1_input.bias', 'score.out_proj.weight', 'score.dense_2.weight', 'score.dense_1_hidden.weight', 'score.dense_2.bias', 'score.dense_3.weight', 'score.dense_1_input.weight', 'score.dense_3.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "02/21/2022 16:42:59 - INFO - __main__ - Freezing model weights\n",
            "Using pad_token, but it is not set yet.\n",
            "02/21/2022 16:42:59 - INFO - __main__ - Set PAD token to EOS: <|endoftext|>\n",
            "Running tokenizer on dataset: 100% 16/16 [00:01<00:00, 14.80ba/s]\n",
            "Running tokenizer on dataset: 100% 2/2 [00:00<00:00, 20.24ba/s]\n",
            "Running tokenizer on dataset: 100% 2/2 [00:00<00:00, 19.19ba/s]\n",
            "02/21/2022 16:43:00 - INFO - __main__ - Sample 1094 of the training set: {'attention_mask': [1, 1, 1, 1], 'input_ids': [72, 1254, 523, 25602], 'labels': 3}.\n",
            "02/21/2022 16:43:00 - INFO - __main__ - Sample 4957 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [72, 716, 22922, 2004, 866, 416, 262, 7666, 286, 852, 9642, 2668, 340, 691, 5645, 510, 1642, 502, 1254, 12733, 286, 1842, 326, 318, 852, 905, 1068, 2402, 502, 703, 460, 1312, 1254, 262, 1842, 290, 8716, 611, 1312, 1254, 2769, 1626, 502, 49284], 'labels': 0}.\n",
            "02/21/2022 16:43:00 - INFO - __main__ - Sample 11928 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [72, 1254, 356, 302, 4379, 783, 318, 257, 19122, 1022, 883, 508, 389, 845, 32064, 379, 262, 2458, 287, 674, 5440, 290, 883, 508, 389, 2138, 300, 7807, 291, 546, 262, 2187, 1517], 'labels': 4}.\n",
            "02/21/2022 16:43:04 - INFO - __main__ - ***** Running training *****\n",
            "02/21/2022 16:43:04 - INFO - __main__ -   Num examples = 16000\n",
            "02/21/2022 16:43:04 - INFO - __main__ -   Num Epochs = 8\n",
            "02/21/2022 16:43:04 - INFO - __main__ -   Instantaneous batch size per device = 16\n",
            "02/21/2022 16:43:04 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "02/21/2022 16:43:04 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "02/21/2022 16:43:04 - INFO - __main__ -   Total optimization steps = 8000\n",
            " 12% 1000/8000 [02:12<14:09,  8.24it/s]02/21/2022 16:45:30 - INFO - __main__ - Epoch 0: {'accuracy': 0.4415}\n",
            " 25% 2000/8000 [04:38<14:23,  6.95it/s]02/21/2022 16:47:56 - INFO - __main__ - Epoch 1: {'accuracy': 0.4675}\n",
            " 38% 3000/8000 [07:04<11:37,  7.16it/s]02/21/2022 16:50:22 - INFO - __main__ - Epoch 2: {'accuracy': 0.4745}\n",
            " 50% 4000/8000 [09:31<07:46,  8.58it/s]02/21/2022 16:52:49 - INFO - __main__ - Epoch 3: {'accuracy': 0.493}\n",
            " 62% 5000/8000 [11:57<06:15,  7.99it/s]02/21/2022 16:55:15 - INFO - __main__ - Epoch 4: {'accuracy': 0.487}\n",
            " 75% 6000/8000 [14:23<04:15,  7.82it/s]02/21/2022 16:57:42 - INFO - __main__ - Epoch 5: {'accuracy': 0.482}\n",
            " 88% 7000/8000 [16:49<02:18,  7.22it/s]02/21/2022 17:00:07 - INFO - __main__ - Epoch 6: {'accuracy': 0.4995}\n",
            "100% 8000/8000 [19:16<00:00,  7.58it/s]02/21/2022 17:02:34 - INFO - __main__ - Epoch 7: {'accuracy': 0.503}\n",
            "02/21/2022 17:02:47 - INFO - __main__ - Test-set evaluation: {'accuracy': 0.5035}\n",
            "Configuration saved in out/gpt2/version4/config.json\n",
            "Model weights saved in out/gpt2/version4/pytorch_model.bin\n",
            "tokenizer config file saved in out/gpt2/version4/tokenizer_config.json\n",
            "Special tokens file saved in out/gpt2/version4/special_tokens_map.json\n",
            "100% 8000/8000 [19:44<00:00,  6.75it/s]\n"
          ]
        }
      ],
      "source": [
        "!python run_glue_no_trainer.py \\\n",
        "  --model_name_or_path gpt2 \\\n",
        "  --train_file data/train.json  \\\n",
        "  --validation_file data/valid.json \\\n",
        "  --test_file data/test.json \\\n",
        "  --per_device_train_batch_size 16 \\\n",
        "  --per_device_eval_batch_size 16 \\\n",
        "  --max_length 128 \\\n",
        "  --freeze_model \\\n",
        "  --custom_model \\\n",
        "  --return_hidden_states \\\n",
        "  --learning_rate 2e-5 \\\n",
        "  --num_train_epochs 8 \\\n",
        "  --output_dir out/gpt2/version4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7Qw4Xh-BTqV"
      },
      "source": [
        "### Version 5\n",
        "#### GPT2ForSequenceClassificationCustomVersion2\n",
        "Dodana zostaÅ‚a nowa warstwa, dodatkowo uruchomiony na 4 epochach. RÃ³Å¼nica w tej wersji polega na zmianie klasyfikacji z 6 labeli na 2. UznaliÅ›my Å¼e ciekawym bÄ™dzie porÃ³wnanie wynikÃ³w i na potrzeby prÃ³b przekonwertujemy nasz dataset emocji tylko na podziaÅ‚ pomiÄ™dzy pozytywnymi, a negatywnymi:\n",
        "- sadness = negative\n",
        "- joy = positive\n",
        "- love = positive\n",
        "- anger = negative\n",
        "- fear = negative\n",
        "- suprise = positive\n",
        "\n",
        "Wyniki prezentujÄ… siÄ™ nastÄ™pujÄ…co:\n",
        "- Epoch 0 accuracy: 0.75\n",
        "- Epoch 1 accuracy: 0.7485\n",
        "- Epoch 2 accuracy: 0.75\n",
        "- Epoch 3 accuracy: 0.7505\n",
        "- Evaluation accurracy: 0.7635"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8kTWizBBTqW",
        "outputId": "e7dc4295-05cc-4f71-cac9-95d80dfb3b41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "02/21/2022 17:02:55 - INFO - __main__ - Distributed environment: NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "Use FP16 precision: False\n",
            "\n",
            "02/21/2022 17:02:55 - WARNING - datasets.builder - Using custom data configuration default-cc22392d4c309154\n",
            "Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-cc22392d4c309154/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426...\n",
            "100% 3/3 [00:00<00:00, 9482.22it/s]\n",
            "100% 3/3 [00:00<00:00, 1173.56it/s]\n",
            "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-cc22392d4c309154/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426. Subsequent calls will reuse this data.\n",
            "100% 3/3 [00:00<00:00, 701.66it/s]\n",
            "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
            "Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
            "Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/gpt2/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
            "loading file https://huggingface.co/gpt2/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "loading file https://huggingface.co/gpt2/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/16a2f78023c8dc511294f0c97b5e10fde3ef9889ad6d11ffaa2a00714e73926e.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
            "loading file https://huggingface.co/gpt2/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/gpt2/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/gpt2/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
            "Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.12.5\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "02/21/2022 17:03:04 - INFO - __main__ - Return hidden states from model: True\n",
            "02/21/2022 17:03:04 - INFO - __main__ - Using implementation from: GPT2ForSequenceClassificationCustom\n",
            "loading weights file https://huggingface.co/gpt2/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/752929ace039baa8ef70fe21cdf9ab9445773d20e733cf693d667982e210837e.323c769945a351daa25546176f8208b3004b6f563438a7603e7932bae9025925\n",
            "All model checkpoint weights were used when initializing GPT2ForSequenceClassificationCustom.\n",
            "\n",
            "Some weights of GPT2ForSequenceClassificationCustom were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.dense_1_hidden.weight', 'score.dense_1_input.weight', 'score.dense_1_hidden.bias', 'score.dense_3.bias', 'score.dense_2.bias', 'score.dense_1_input.bias', 'score.dense_3.weight', 'score.out_proj.weight', 'score.dense_2.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "02/21/2022 17:03:08 - INFO - __main__ - Freezing model weights\n",
            "Using pad_token, but it is not set yet.\n",
            "02/21/2022 17:03:08 - INFO - __main__ - Set PAD token to EOS: <|endoftext|>\n",
            "Running tokenizer on dataset: 100% 16/16 [00:01<00:00, 15.37ba/s]\n",
            "Running tokenizer on dataset: 100% 2/2 [00:00<00:00, 20.36ba/s]\n",
            "Running tokenizer on dataset: 100% 2/2 [00:00<00:00, 20.16ba/s]\n",
            "02/21/2022 17:03:09 - INFO - __main__ - Sample 12780 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [72, 1265, 3589, 1312, 892, 546, 340, 3589, 1312, 1254, 19283], 'labels': 0}.\n",
            "02/21/2022 17:03:09 - INFO - __main__ - Sample 3674 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [72, 1254, 517, 2695, 351, 644, 1312, 423, 8793, 290, 1312, 760, 611, 1312, 836, 256, 3551, 1909, 612, 32660, 991, 307, 257, 9439], 'labels': 1}.\n",
            "02/21/2022 17:03:09 - INFO - __main__ - Sample 14780 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [320, 635, 4203, 43210, 290, 1312, 765, 284, 12012, 345, 351, 257, 1178, 517, 1468, 3088, 290, 2081, 1641, 14296], 'labels': 0}.\n",
            "02/21/2022 17:03:13 - INFO - __main__ - ***** Running training *****\n",
            "02/21/2022 17:03:13 - INFO - __main__ -   Num examples = 16000\n",
            "02/21/2022 17:03:13 - INFO - __main__ -   Num Epochs = 4\n",
            "02/21/2022 17:03:13 - INFO - __main__ -   Instantaneous batch size per device = 24\n",
            "02/21/2022 17:03:13 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 24\n",
            "02/21/2022 17:03:13 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "02/21/2022 17:03:13 - INFO - __main__ -   Total optimization steps = 2668\n",
            "  8% 207/2668 [00:42<08:34,  4.78it/s]"
          ]
        }
      ],
      "source": [
        "!python run_glue_no_trainer.py \\\n",
        "  --model_name_or_path gpt2 \\\n",
        "  --train_file data/train_binary.json  \\\n",
        "  --validation_file data/valid_binary.json \\\n",
        "  --test_file data/test_binary.json \\\n",
        "  --per_device_train_batch_size 24 \\\n",
        "  --per_device_eval_batch_size 24 \\\n",
        "  --freeze_model \\\n",
        "  --custom_model \\\n",
        "  --return_hidden_states \\\n",
        "  --max_length 128 \\\n",
        "  --learning_rate 2e-5 \\\n",
        "  --num_train_epochs 4 \\\n",
        "  --output_dir out/gpt2/version5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zum0uHjoBTqX"
      },
      "source": [
        "## RoBERTa\n",
        "Model RoBERTa zostaÅ‚ zaproponowany w ksiÄ…Å¼ce RoBERTa: A Robustly Optimized BERT Pretraining Approach przez Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov. Jest on oparty na modelu BERT firmy Google wydanym w 2018 roku."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3AjEz_HBTqZ"
      },
      "source": [
        "Podstawowy model RoBERTa\n",
        "- Epoch 0: accuracy: 0.92\n",
        "- Evaluation: accuracy: 0.92"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPVxToMfBTqa"
      },
      "outputs": [],
      "source": [
        "! python run_glue_no_trainer.py \\\n",
        "  --model_name_or_path roberta-base \\\n",
        "  --train_file data/train.json  \\\n",
        "  --validation_file data/valid.json \\\n",
        "  --test_file data/test.json \\\n",
        "  --per_device_train_batch_size 24 \\\n",
        "  --per_device_eval_batch_size 24 \\\n",
        "  --max_length 128 \\\n",
        "  --learning_rate 2e-5 \\\n",
        "  --num_train_epochs 1 \\\n",
        "  --output_dir out/emotion/roberta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrrpIULCBTqb"
      },
      "source": [
        "### Version 2\n",
        "Kod poniÅ¼ej odnosi siÄ™ do customowego modelu zapisanego w pliku roberta.py. ZwiÄ™kszona zostaÅ‚a liczba epok, a takÅ¼e zmniejszony batchsize na zbiorze treningowym i eval. Dodatkowo zostaÅ‚y zamroÅ¼one wagi (nie w gÅ‚owie klasyfikacji). Learning rate i maksymalna dÅ‚ugoÅ›Ä‡ sekwencji pozostaÅ‚a taka sama.\n",
        "\n",
        "- Epoch 0: accuracy: 0.35\n",
        "- Epoch 1: accuracy: 0.40\n",
        "- Epoch 2: accuracy: 0.36\n",
        "- Epoch 3: accuracy: 0.47\n",
        "- Epoch 4: accuracy: 0.50\n",
        "- Epoch 5: accuracy: 0.52\n",
        "- Epoch 6: accuracy: 0.52\n",
        "- Epoch 7: accuracy: 0.52\n",
        "- Evaluation: accuracy: 0.52"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrPCAI61BTqc"
      },
      "outputs": [],
      "source": [
        "! python run_glue_no_trainer.py \\\n",
        "  --model_name_or_path roberta-base \\\n",
        "  --train_file data/train.json  \\\n",
        "  --validation_file data/valid.json \\\n",
        "  --test_file data/test.json \\\n",
        "  --per_device_train_batch_size 16 \\\n",
        "  --per_device_eval_batch_size 16 \\\n",
        "  --max_length 128 \\\n",
        "  --freeze_model \\\n",
        "  --learning_rate 2e-5 \\\n",
        "  --num_train_epochs 8 \\\n",
        "  --custom_model \\\n",
        "  --output_dir out/emotion/roberta3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzptYXT7BTqc"
      },
      "source": [
        "### Version 3\n",
        "Kod poniÅ¼ej odnosi siÄ™ do pliku robertaforward.py. Batch zostaÅ‚ zmniejszony do 12, maksymalna dÅ‚ugoÅ›Ä‡ sekwencji (max_length) zostaje taka sama. Dodatkowo, dodany zostaÅ‚ pooling layer. Wagi (nie w gÅ‚owie klasyfikacji) zostaÅ‚y zamroÅ¼one. Model byÅ‚ trenowany w 12 epokach.\n",
        "\n",
        "- Epoch 0: accuracy: 0.35\n",
        "- Epoch 1: accuracy: 0.40\n",
        "- Epoch 2: accuracy: 0.32\n",
        "- Epoch 3: accuracy: 0.35\n",
        "- Epoch 4: accuracy: 0.51\n",
        "- Epoch 5: accuracy: 0.35\n",
        "- Epoch 6: accuracy: 0.35\n",
        "- Epoch 7: accuracy: 0.51\n",
        "- Epoch 8: accuracy: 0.35\n",
        "- Epoch 9: accuracy: 0.35\n",
        "- Epoch 10: accuracy: 0.35\n",
        "- Epoch 11 accuracy: 0.35\n",
        "\n",
        "- Evaluation: accuracy: 0.38"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEQisuvvBTqd"
      },
      "outputs": [],
      "source": [
        "! python run_glue_no_trainer2.py \\\n",
        "  --model_name_or_path roberta-base \\\n",
        "  --train_file data/train.json  \\\n",
        "  --validation_file data/valid.json \\\n",
        "  --test_file data/test.json \\\n",
        "  --per_device_train_batch_size 12 \\\n",
        "  --per_device_eval_batch_size 12 \\\n",
        "  --max_length 128 \\\n",
        "  --freeze_model \\\n",
        "  --learning_rate 2e-5 \\\n",
        "  --num_train_epochs 12 \\\n",
        "  --custom_model \\\n",
        "  --output_dir out/emotion/roberta4\n",
        "   \n",
        "  # --lr_scheduler_type \"linear\" \\"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-_LreALBTqd"
      },
      "source": [
        "### Version 4\n",
        "Kod poniÅ¼ej odnosi siÄ™ do pliku robertasmallhead.py. Batchsize zostaÅ‚ zwiÄ™kszony do 32, dodatkowo learning rate zostaÅ‚ zmieniony na 3*10^-5.\n",
        "\n",
        "- Epoch 0: accuracy: 0.35\n",
        "- Epoch 1: accuracy: 0.39\n",
        "- Epoch 2: accuracy: 0.47\n",
        "- Epoch 3: accuracy: 0.49\n",
        "- Epoch 4: accuracy: 0.51\n",
        "- Epoch 5: accuracy: 0.50\n",
        "- Epoch 6: accuracy: 0.51\n",
        "- Epoch 7: accuracy: 0.52\n",
        "- Epoch 8: accuracy: 0.52\n",
        "- Epoch 9: accuracy: 0.52\n",
        "- Epoch 10: accuracy: 0.52\n",
        "- Epoch 11 accuracy: 0.52\n",
        "- Epoch 12: accuracy: 0.53\n",
        "\n",
        "- Evaluation: accuracy: 0.51"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REpd8Q1DBTqe"
      },
      "outputs": [],
      "source": [
        "! python run_glue_no_trainer3.py \\\n",
        "  --model_name_or_path roberta-base \\\n",
        "  --train_file data/train.json  \\\n",
        "  --validation_file data/valid.json \\\n",
        "  --test_file data/test.json \\\n",
        "  --per_device_train_batch_size 32 \\\n",
        "  --per_device_eval_batch_size 32 \\\n",
        "  --max_length 128 \\\n",
        "  --freeze_model \\\n",
        "  --learning_rate 3e-5 \\\n",
        "  --num_train_epochs 12 \\\n",
        "  --custom_model \\\n",
        "  --output_dir out/emotion/roberta5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtysLJf-BTqe"
      },
      "source": [
        "### Version 5\n",
        "Kod poniÅ¼ej opiera siÄ™ o plik roberta.py. Zmieniona zostaÅ‚a liczba epok, batch size i learning rate. UÅ¼yte zostaÅ‚y hidden states.\n",
        "\n",
        "- Epoch 0: accuracy: 0.35\n",
        "- Epoch 1: accuracy: 0.35\n",
        "- Epoch 2: accuracy: 0.44\n",
        "- Epoch 3: accuracy: 0.56\n",
        "- Epoch 4: accuracy: 0.57\n",
        "- Epoch 5: accuracy: 0.57\n",
        "- Epoch 6: accuracy: 0.57\n",
        "- Epoch 7: accuracy: 0.57\n",
        "\n",
        "- Evaluation: accuracy: 0.57"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvG2BNdbBTqf"
      },
      "outputs": [],
      "source": [
        "! python run_glue_no_trainer.py \\\n",
        "  --model_name_or_path roberta-base \\\n",
        "  --train_file data/train.json  \\\n",
        "  --validation_file data/valid.json \\\n",
        "  --test_file data/test.json \\\n",
        "  --per_device_train_batch_size 26 \\\n",
        "  --per_device_eval_batch_size 26 \\\n",
        "  --max_length 128 \\\n",
        "  --return_hidden_states \\\n",
        "  --learning_rate 2e-7 \\\n",
        "  --num_train_epochs 8 \\\n",
        "  --custom_model \\\n",
        "  --output_dir out/emotion/roberta6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_BypMB4BTqf"
      },
      "source": [
        "## T5\n",
        "Podstawowy model T5-small\n",
        "- Epoch 0: accuracy 0.46987951807228917\n",
        "- Epoch 1: accuracy 0.5559380378657487\n",
        "- Epoch 2: accuracy 0.6161790017211703\n",
        "- Epoch 3: accuracy 0.6643717728055077\n",
        "- Epoch 4: accuracy 0.6884681583476764\n",
        "- Epoch 5: accuracy 0.7039586919104991\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_dC2bWZBTqg"
      },
      "outputs": [],
      "source": [
        "!python run_translation_no_trainer.py \\\n",
        "  --model_name_or_path t5-small \\\n",
        "  --train_file data/translations-train.json \\\n",
        "  --validation_file data/translations-valid.json \\\n",
        "  --test_file data/translations-test.json \\\n",
        "  --per_device_train_batch_size 8 \\\n",
        "  --per_device_eval_batch_size 8 \\\n",
        "  --source_prefix \"emotion classification\" \\\n",
        "  --max_source_length 256 \\\n",
        "  --max_target_length 128 \\q\n",
        "  --max_length 128 \\\n",
        "  --num_train_epochs 6 \\\n",
        "  --freeze_encoder \\\n",
        "  --output_dir out/emotion/t5_1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0Ob_KzOBTqg"
      },
      "source": [
        "### Version 2 binary\n",
        "- Epoch 0: accuracy 0.825\n",
        "- Epoch 1: accuracy 0.85\n",
        "- Epoch 2: accuracy 0.855\n",
        "- Epoch 3: accuracy 0.895\n",
        "- Epoch 4: accuracy 0.9\n",
        "- Epoch 5: accuracy 0.915"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rc7SHJpBTqh"
      },
      "outputs": [],
      "source": [
        "!python run_translation_no_trainer_binary.py \\\n",
        "  --model_name_or_path t5-small \\\n",
        "  --train_file data/translations-train_binary.json \\\n",
        "  --validation_file data/translations-valid_binary.json \\\n",
        "  --test_file data/translations-test_binary.json \\\n",
        "  --per_device_train_batch_size 16 \\\n",
        "  --per_device_eval_batch_size 16 \\\n",
        "  --source_prefix \"emotion classification\" \\\n",
        "  --max_source_length 256 \\\n",
        "  --max_target_length 128 \\\n",
        "  --max_length 128 \\\n",
        "  --num_train_epochs 6 \\\n",
        "  --output_dir out/emotion/t5_2"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "project.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e5b353287cba4e2b91ef611c44990330": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cdfdff424b174268a547336a85b5f43e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6f022cfad7df4927ab4a8bfb82a0ea74",
              "IPY_MODEL_0bd1a03796b241e6bc947bee56cbfd9b",
              "IPY_MODEL_7d1cf194f8254611b72435af1bfa05d4"
            ]
          }
        },
        "cdfdff424b174268a547336a85b5f43e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6f022cfad7df4927ab4a8bfb82a0ea74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_76e9d4b880f74bdf85780c4dc6f6494c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: ",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f8a3ef6dcf3044a4b86fa73f38a1dedc"
          }
        },
        "0bd1a03796b241e6bc947bee56cbfd9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3e9b0f4310074f568af4aee5a4754aca",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1655,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1655,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ab660e703b824b37a60e2fe283411f0f"
          }
        },
        "7d1cf194f8254611b72435af1bfa05d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3f241f591cdc419eb6cef53acad50912",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3.62k/? [00:00&lt;00:00, 13.4kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1d3ebfc2fd0c426182248cc4bba97303"
          }
        },
        "76e9d4b880f74bdf85780c4dc6f6494c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f8a3ef6dcf3044a4b86fa73f38a1dedc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3e9b0f4310074f568af4aee5a4754aca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ab660e703b824b37a60e2fe283411f0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3f241f591cdc419eb6cef53acad50912": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1d3ebfc2fd0c426182248cc4bba97303": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e591012c848248bfb64ef463f2e1f097": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dc04d6f4370d49408580c3c146e587bc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b9ae3603130640dc8dfedac3385574f0",
              "IPY_MODEL_e4c4e484ae40404c894dcaeb0c7ad242",
              "IPY_MODEL_fd343007a5d8403187bccd877511c7fc"
            ]
          }
        },
        "dc04d6f4370d49408580c3c146e587bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b9ae3603130640dc8dfedac3385574f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7c8f9331f07949c0ba413497cf2eb2ef",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: ",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cb58a69e554d4a40a6e3cd6019d28a69"
          }
        },
        "e4c4e484ae40404c894dcaeb0c7ad242": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_970a405cd6f44606b4692fab7f23f9e4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1611,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1611,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1108573852bc4ea4a3f96a1629f665bc"
          }
        },
        "fd343007a5d8403187bccd877511c7fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cc5e139178f14661be798a051b2084c0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3.28k/? [00:00&lt;00:00, 74.7kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0a42381aac5f4d5185605fc4237a6325"
          }
        },
        "7c8f9331f07949c0ba413497cf2eb2ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cb58a69e554d4a40a6e3cd6019d28a69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "970a405cd6f44606b4692fab7f23f9e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1108573852bc4ea4a3f96a1629f665bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cc5e139178f14661be798a051b2084c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0a42381aac5f4d5185605fc4237a6325": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3388d361cc5f418d869344763252e4f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6a522409c2c7470b8740a6cf810542f4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_937d6b8be0ac4c368f41fd99c9277386",
              "IPY_MODEL_0a7d64d24ba94b9f8394aa33604f7a96",
              "IPY_MODEL_90374892c74749a08a5cd07840ad432f"
            ]
          }
        },
        "6a522409c2c7470b8740a6cf810542f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "937d6b8be0ac4c368f41fd99c9277386": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_402b397e45fe4778983903e11ca6ccf6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: ",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_288aa13994404db0b305c7a6a96ec508"
          }
        },
        "0a7d64d24ba94b9f8394aa33604f7a96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a5cc0cad6d914b0db9e073db58258038",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_865e589a601d4cdbbcf13c452bfe04a1"
          }
        },
        "90374892c74749a08a5cd07840ad432f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_70104b66783947ae8f6294f62f8b34c9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.66M/? [00:00&lt;00:00, 4.90MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_648b781bd2194755910cebf273f1cb5a"
          }
        },
        "402b397e45fe4778983903e11ca6ccf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "288aa13994404db0b305c7a6a96ec508": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a5cc0cad6d914b0db9e073db58258038": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "865e589a601d4cdbbcf13c452bfe04a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "70104b66783947ae8f6294f62f8b34c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "648b781bd2194755910cebf273f1cb5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "57d086ab81824bf0af1f039ce839a738": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bb46a2b88f904787a0731923429d08e9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_88d739caeea34142a2f57aec393a9bb7",
              "IPY_MODEL_79ad75e6fb7c44baa1697c8b84b47796",
              "IPY_MODEL_00ebc78527c146e89a833640cee87cb0"
            ]
          }
        },
        "bb46a2b88f904787a0731923429d08e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "88d739caeea34142a2f57aec393a9bb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1a7e2282193e4b8a923beeb560f69675",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: ",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b96da57ccacf47e499ebe2a364ab10c0"
          }
        },
        "79ad75e6fb7c44baa1697c8b84b47796": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_366a26758a97451685151081eb14809a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cbc4c16889034d4cab98e992bcdd4864"
          }
        },
        "00ebc78527c146e89a833640cee87cb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6ffe806afe4b464f9d9384f5dc284476",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 204k/? [00:00&lt;00:00, 835kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_79f9df32b6964c5d9eebdc45913984e1"
          }
        },
        "1a7e2282193e4b8a923beeb560f69675": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b96da57ccacf47e499ebe2a364ab10c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "366a26758a97451685151081eb14809a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cbc4c16889034d4cab98e992bcdd4864": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6ffe806afe4b464f9d9384f5dc284476": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "79f9df32b6964c5d9eebdc45913984e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ee3be597f1154d318ed0173b9caff6ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5ff00ef858414a6d96440336a3d06b3a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0e384d940c5a4fa592d2530c0d767107",
              "IPY_MODEL_766173b8f9d741eba0af878b3b1f489b",
              "IPY_MODEL_11be1e2f65b044079be97db90a2ec0f7"
            ]
          }
        },
        "5ff00ef858414a6d96440336a3d06b3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0e384d940c5a4fa592d2530c0d767107": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_187554fbce504ab89720a8b9274de559",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: ",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b7f0715ac3bf4bbe8956b15c015a2d63"
          }
        },
        "766173b8f9d741eba0af878b3b1f489b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_068c80f0ba584831a3f7b1442f111fa0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_57e3fec192f4401a9377812dab43b1ce"
          }
        },
        "11be1e2f65b044079be97db90a2ec0f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4ec9359ffb424a81bd932e3670864abf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 207k/? [00:00&lt;00:00, 315kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e0e8ac3dc7a14a5bac6c7015ae7544f4"
          }
        },
        "187554fbce504ab89720a8b9274de559": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b7f0715ac3bf4bbe8956b15c015a2d63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "068c80f0ba584831a3f7b1442f111fa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "57e3fec192f4401a9377812dab43b1ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ec9359ffb424a81bd932e3670864abf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e0e8ac3dc7a14a5bac6c7015ae7544f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "283f704832254e038af2068f8e0bb5c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9ee7b459a60e41669bf9482760a0acc8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_13e484f101744bf88d22bb189d6bed83",
              "IPY_MODEL_08bf77609b5a4cca89d0fb495bd9367c",
              "IPY_MODEL_31a8e0bb8bb54505938b2f370d930cbd"
            ]
          }
        },
        "9ee7b459a60e41669bf9482760a0acc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "13e484f101744bf88d22bb189d6bed83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a458752b249845729cc1dae0a9e5d458",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0244fb841b4543939a9c413e60b9b8dc"
          }
        },
        "08bf77609b5a4cca89d0fb495bd9367c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ad407122874442a6a9c07bcfd3fc6e2f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0ec96581c3124816940c96ec41f0ec17"
          }
        },
        "31a8e0bb8bb54505938b2f370d930cbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_05f2858ad9d349dbb4156c3777fbdd57",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 14617/0 [00:00&lt;00:00, 25732.12 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_11733b63339d407195c2c87699671611"
          }
        },
        "a458752b249845729cc1dae0a9e5d458": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0244fb841b4543939a9c413e60b9b8dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ad407122874442a6a9c07bcfd3fc6e2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0ec96581c3124816940c96ec41f0ec17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "05f2858ad9d349dbb4156c3777fbdd57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "11733b63339d407195c2c87699671611": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d211596c0dcd4b6597cbd72e33bc406e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_761ef443f508497f8002dd0d19876ba0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_342b37358cc6497cb08fa657c6a2132d",
              "IPY_MODEL_8cab94a65390465ebb334e079b75246c",
              "IPY_MODEL_ed76b8cea88e46248734664bf6ea5666"
            ]
          }
        },
        "761ef443f508497f8002dd0d19876ba0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "342b37358cc6497cb08fa657c6a2132d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2e0d56f5cded498d9e350ce288c8f43a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3a5dea16cff44fe3b322c1afd2d078e7"
          }
        },
        "8cab94a65390465ebb334e079b75246c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_dc7100c6b706448386bc8e1036593979",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ae6c0393aa934c6f86a28bff6ca253df"
          }
        },
        "ed76b8cea88e46248734664bf6ea5666": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_422bc3d46ccf49a5ba85a88acad3465f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 686/0 [00:00&lt;00:00, 6856.18 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a4a39ff237784a1f941791cb9d2d3cfd"
          }
        },
        "2e0d56f5cded498d9e350ce288c8f43a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3a5dea16cff44fe3b322c1afd2d078e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dc7100c6b706448386bc8e1036593979": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ae6c0393aa934c6f86a28bff6ca253df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "422bc3d46ccf49a5ba85a88acad3465f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a4a39ff237784a1f941791cb9d2d3cfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "40ab9a3eb5fc47679032946ed4ef1e89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_03ce62c360644c539371ecafdf0fd9dc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ab367a398a5d45ba8c31946fb2a8c3e1",
              "IPY_MODEL_8e4f28d5c9fb49848364eb19f4e30712",
              "IPY_MODEL_40b746313f0c444e942049e39cb9ca40"
            ]
          }
        },
        "03ce62c360644c539371ecafdf0fd9dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ab367a398a5d45ba8c31946fb2a8c3e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ff510201fbd14ed1a30e63be72b52a67",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c05deeb897e2489da33dc53234ddc9ff"
          }
        },
        "8e4f28d5c9fb49848364eb19f4e30712": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_777aa998ba6b4a66ab7c40c974d16792",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4034d482358e44dc823888959e2f4cf6"
          }
        },
        "40b746313f0c444e942049e39cb9ca40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_02160736a23c469bb7774ea17fd5edf8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 579/0 [00:00&lt;00:00, 5785.94 examples/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_756476db0e114c9aba061914aae489fc"
          }
        },
        "ff510201fbd14ed1a30e63be72b52a67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c05deeb897e2489da33dc53234ddc9ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "777aa998ba6b4a66ab7c40c974d16792": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4034d482358e44dc823888959e2f4cf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": "20px",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "02160736a23c469bb7774ea17fd5edf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "756476db0e114c9aba061914aae489fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7cd568581fd4421caf28226b36c09ef2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5ed84338d0d24649810c36768f587952",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_af366e73d49a468bb953b0112b5e872c",
              "IPY_MODEL_326fcf344050406a976650fc5004faff",
              "IPY_MODEL_55f99e4f573047c2b1d1dc49a369ed9c"
            ]
          }
        },
        "5ed84338d0d24649810c36768f587952": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "af366e73d49a468bb953b0112b5e872c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_40316406b5854cd7af1baf4ab0dbf5ab",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3c5802d82d1b4a5d9331a08df5a6f4bb"
          }
        },
        "326fcf344050406a976650fc5004faff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4f75ec098362434bb463a51a47c647ff",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_95c8ecb35c194817a9f7d4a1a6faa944"
          }
        },
        "55f99e4f573047c2b1d1dc49a369ed9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5f1c339e22da4d43a87367b840c833eb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3/3 [00:00&lt;00:00, 51.34it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e80a2447320c417eb0f34794edeee389"
          }
        },
        "40316406b5854cd7af1baf4ab0dbf5ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3c5802d82d1b4a5d9331a08df5a6f4bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4f75ec098362434bb463a51a47c647ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "95c8ecb35c194817a9f7d4a1a6faa944": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5f1c339e22da4d43a87367b840c833eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e80a2447320c417eb0f34794edeee389": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}